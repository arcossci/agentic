{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arcossci/agentic/blob/master/adk_tutorial_ES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construye su primer equipo de agente inteligente: un bot de clima progresivo con ADK\n",
        "\n",
        "Este tutorial se extiende desde [QuickStart Ejemplo] (https://google.github.io/adk-docs/get-started/quickstart/) para [agente kit de desarrollo] (https://google.github.io/adk-docs/get-started/).Ahora, estás listo para sumergirte más profundo y construir un sistema más sofisticado, ** múltiple agente **.\n",
        "\n",
        "Nos embarcaremos en la construcción de un ** equipo de agente de bot **, colocando progresivamente las características avanzadas en una base simple.Comenzando con un solo agente que puede buscar el clima, agregaremos incrementalmente capacidades como:\n",
        "\n",
        "* Aprovechando diferentes modelos AI (Gemini, GPT, Claude).\n",
        "* Diseño de sub-agentes especializados para tareas distintas (como saludos y despedidas).\n",
        "* Habilitando la delegación inteligente entre agentes.\n",
        "* Darle a los agentes memoria utilizando el estado de sesión persistente.\n",
        "* Implementación de barandillas de seguridad cruciales utilizando devoluciones de llamada.\n",
        "\n",
        "** ¿Por qué un equipo de botes meteorológicos? **\n",
        "\n",
        "Este caso de uso, aunque aparentemente simple, proporciona un lienzo práctico y identificable para explorar conceptos de ADK básicos esenciales para construir aplicaciones de agente complejas del mundo real.Aprenderá a estructurar las interacciones, administrar el estado, garantizar la seguridad y orquestar múltiples \"cerebros\" de IA trabajando juntos.\n",
        "\n",
        "** ¿Qué es ADK de nuevo? **\n",
        "\n",
        "Como recordatorio, ADK es un marco de Python diseñado para optimizar el desarrollo de aplicaciones alimentadas por modelos de idiomas grandes (LLM).Ofrece bloques de construcción robustos para crear agentes que puedan razonar, planificar, utilizar herramientas, interactuar dinámicamente con los usuarios y colaborar de manera efectiva dentro de un equipo.\n",
        "\n",
        "** En este tutorial avanzado, dominará: **\n",
        "\n",
        "*✅ ** Definición y uso de herramientas: ** Crafting Python Functions ('Tools`) que otorgan a los agentes habilidades específicas (como obtener datos) e instruir a los agentes sobre cómo usarlas de manera efectiva.\n",
        "*✅ ** Flexibilidad multi-LLM: ** Configuración de agentes para utilizar varios LLM principales (Gemini, GPT-4O, Claude Sonnet) a través de la integración de litellm, lo que le permite elegir el mejor modelo para cada tarea.\n",
        "*✅ ** Delegación y colaboración del agente: ** Diseño de subcásgentes especializados y habilita el enrutamiento automático (`flujo automático ') de las solicitudes de los usuarios al agente más apropiado dentro de un equipo.\n",
        "*✅ ** Estado de sesión para la memoria: ** Utilizando el `estado de sesión` y` herramientas de toolcontext` para permitir que los agentes recuerden la información en los giros conversacionales, lo que lleva a más interacciones contextuales.\n",
        "*✅ ** Las barandillas de seguridad con devoluciones de llamada: ** Implementación de `antes_model_callback` y` antes_tool_callback` para inspeccionar, modificar o bloquear las solicitudes/uso de la herramienta basado en reglas predefinidas, mejorar la seguridad y el control de la aplicación.\n",
        "\n",
        "** Expectativa estatal final: **\n",
        "\n",
        "Al completar este tutorial, habrá creado un sistema funcional de botes meteorológicos de varios agentes.Este sistema no solo proporcionará información meteorológica, sino que también manejará las sutilezas de conversación, recuerde la última ciudad verificada y operará dentro de los límites de seguridad definidos, todos orquestados usando ADK.\n",
        "\n",
        "** Requisitos previos: **\n",
        "\n",
        "*✅ ** Comprensión sólida de la programación de Python. **\n",
        "*✅ ** Familiaridad con modelos de idiomas grandes (LLM), API y el concepto de agentes. **\n",
        "*❗ ** Crucialmente: finalización de los tutoriales ADK QuickStart o el conocimiento fundamental equivalente de los conceptos básicos de ADK (agente, corredor, sessionservice, uso básico de herramientas). ** Este tutorial se basa directamente en esos conceptos.\n",
        "*✅ ** API teclas ** Para los LLM que tiene la intención de usar (por ejemplo, Google AI Studio para Gemini, plataforma OpenAI, consola antrópica).\n",
        "\n",
        "** ¿Listo para construir su equipo de agentes?Vamos a sumergirnos! **"
      ],
      "metadata": {
        "id": "Np0plMPXRvoq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ARCoeUZCRNGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45aa0b53-38f0-4be4-f5b6-fc42321b0d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/google-cloud-secret-manager/\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.5/215.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.3/332.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallation complete.\n"
          ]
        }
      ],
      "source": [
        "# Title Paso 0: Configuración e instalación\n",
        "# Instale ADK y Litellm para soporte de múltiples modelos\n",
        "\n",
        "!pip install google-adk -q\n",
        "!pip install litellm -q\n",
        "\n",
        "print(\"Installation complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Importar bibliotecas necesarias\n",
        "import os\n",
        "import asyncio\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "from google.colab import userdata\n",
        "\n",
        "import warnings\n",
        "# Ignorar todas las advertencias\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "id": "sbwxKypOSBkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5517093-5085-4a00-aa07-6a6898c231ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Configure las teclas API (¡reemplace con sus claves reales!)\n",
        "\n",
        "# --- IMPORTANTE: Reemplace los marcadores de posición con sus claves API reales ---\n",
        "\n",
        "# Gemini API Key (Obtenga el estudio de Google AI: https://aistudio.google.com/app/apikey)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "# Clave de API de OpenAI (obtenga de la plataforma Operai: https://platform.openai.com/api- keys)\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Clave de API antrópica (obtenga de la consola antrópica: https://console.anthropic.com/settings/keys)\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "\n",
        "\n",
        "# --- Verificar claves (verificación opcional) ---\n",
        "print(\"API Keys Set:\")\n",
        "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
        "\n",
        "# Configurar ADK para usar las teclas API directamente (no Vertex AI para esta configuración de múltiples modelos)\n",
        "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
        "\n",
        "\n",
        "# @markdown\n"
      ],
      "metadata": {
        "id": "3mNsVI5eSDOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c1cb52b-fe81-43ce-91c8-5a0d89aa4aea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Keys Set:\n",
            "Google API Key set: Yes\n",
            "OpenAI API Key set: Yes\n",
            "Anthropic API Key set: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Definir constantes de modelo para facilitar el uso ---\n",
        "\n",
        "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash-exp\"\n",
        "\n",
        "# Nota: Los nombres de modelos específicos pueden cambiar.Consulte la documentación de litellm/proveedor.\n",
        "MODEL_GPT_4O = \"openai/gpt-4o-mini\"\n",
        "MODEL_CLAUDE_SONNET = \"anthropic/claude-3-sonnet-20240229\"\n",
        "\n",
        "\n",
        "print(\"\\nEnvironment configured.\")"
      ],
      "metadata": {
        "id": "MI_qvZJrSJuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0e1c38-f98c-48a2-9f60-f85517e1c534"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Environment configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Paso 1: Su primer agente \\- Búsqueda meteorológica básica\n",
        "\n",
        "Comencemos construyendo el componente fundamental de nuestro bot: un solo agente capaz de realizar una tarea específica: buscar información meteorológica.Esto implica crear dos piezas principales:\n",
        "\n",
        "1. ** Una herramienta: ** Una función de Python que equipa al agente con la*habilidad*para obtener datos meteorológicos.\n",
        "2. ** Un agente: ** El AI \"cerebro\" que comprende la solicitud del usuario, sabe que tiene una herramienta meteorológica y decide cuándo y cómo usarla.\n",
        "\n",
        "---\n",
        "\n",
        "** 1 \\.Defina la herramienta (`get_weather`) **\n",
        "\n",
        "En ADK, ** Herramientas ** son los bloques de construcción que brindan a los agentes capacidades concretas más allá de la generación de texto.Típicamente son funciones de Python regulares que realizan acciones específicas, como llamar a una API, consultar una base de datos o realizar cálculos.\n",
        "\n",
        "Nuestra primera herramienta proporcionará un informe meteorológico * simulado *.Esto nos permite centrarnos en la estructura del agente sin necesidad de claves API externas todavía.Más tarde, podría intercambiar fácilmente esta función simulada con una que llame a un servicio meteorológico real.\n",
        "\n",
        "** Concepto clave: los documentos son cruciales \\! ** El LLM del agente depende en gran medida del ** documento ** ** para comprender:\n",
        "\n",
        "* * Qué * hace la herramienta.\n",
        "* * Cuando * usarlo.\n",
        "* * Qué argumentos * requiere (`ciudad: str`).\n",
        "* * Qué información * devuelve.\n",
        "\n",
        "** Las mejores prácticas: ** Escribe documentos claros, descriptivos y precisos para tus herramientas.Esto es esencial para que el LLM use la herramienta correctamente."
      ],
      "metadata": {
        "id": "F7LZM3ysSOMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Defina la herramienta get_weather\n",
        "def get_weather(city: str) -> dict:\n",
        "    \"\"\"Retrieves the current weather report for a specified city.\n",
        "\n",
        "    Args:\n",
        "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the weather information.\n",
        "              Includes a 'status' key ('success' or 'error').\n",
        "              If 'success', includes a 'report' key with weather details.\n",
        "              If 'error', includes an 'error_message' key.\n",
        "    \"\"\"\n",
        "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
        "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
        "\n",
        "# # Datos meteorológicos simulados\n",
        "    mock_weather_db = {\n",
        "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25°C.\"},\n",
        "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15°C.\"},\n",
        "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\"},\n",
        "    }\n",
        "\n",
        "    if city_normalized in mock_weather_db:\n",
        "        return mock_weather_db[city_normalized]\n",
        "    else:\n",
        "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
        "\n",
        "# Ejemplo de uso de la herramienta (prueba opcional)\n",
        "print(get_weather(\"New York\"))\n",
        "print(get_weather(\"Paris\"))"
      ],
      "metadata": {
        "id": "ILy7YTCbSRAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28daa9ba-0b98-430d-8e51-3fd6e64ae8c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: New York ---\n",
            "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
            "--- Tool: get_weather called for city: Paris ---\n",
            "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 2 \\.Defina el agente (`Weather_agent`) **\n",
        "\n",
        "Ahora, creemos el ** agente ** mismo.Un `agente` en ADK orquesta la interacción entre el usuario, el LLM y las herramientas disponibles.\n",
        "\n",
        "Lo configuramos con varios parámetros clave:\n",
        "\n",
        "* `Nombre`: un identificador único para este agente (por ejemplo,\" clima \\ _agent \\ _v1 \").\n",
        "* `Model`: Especifica qué LLM usar (por ejemplo,` model_gemini_2_5_pro`).Comenzaremos con un modelo de Géminis específico.\n",
        "* `Descripción`: un resumen conciso del propósito general del agente.Esto se vuelve crucial más adelante cuando otros agentes deben decidir si delegar tareas a * este * agente.\n",
        "* `Instrucción`: orientación detallada para el LLM sobre cómo comportarse, su personalidad, sus objetivos y específicamente * cómo y cuándo * utilizar sus 'herramientas' asignadas.\n",
        "* `Herramientas`: una lista que contiene las funciones reales de la herramienta Python que el agente puede usar (por ejemplo,` [get_weather] `).\n",
        "\n",
        "** Las mejores prácticas: ** Proporcione indicaciones claras y específicas de `instrucciones`.Cuanto más detalladas son las instrucciones, mejor será la LLM para comprender su papel y cómo usar sus herramientas de manera efectiva.Sea explícito sobre el manejo de errores si es necesario.\n",
        "\n",
        "** Las mejores prácticas: ** elige valores descriptivos de `nombre` y` description`.Estos se usan internamente por ADK y son vitales para características como la delegación automática (cubierto más adelante)."
      ],
      "metadata": {
        "id": "hAM0BqGWSTo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Defina el agente meteorológico\n",
        "# Use una de las constantes modelo definidas anteriormente\n",
        "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Starting with Gemini\n",
        "\n",
        "weather_agent = Agent(\n",
        "    name=\"weather_agent_v1\",\n",
        "    model=AGENT_MODEL, # Can be a string for Gemini or a LiteLlm object\n",
        "    description=\"Provides weather information for specific cities.\",\n",
        "    instruction=\"You are a helpful weather assistant. \"\n",
        "                \"When the user asks for the weather in a specific city, \"\n",
        "                \"use the 'get_weather' tool to find the information. \"\n",
        "                \"If the tool returns an error, inform the user politely. \"\n",
        "                \"If the tool is successful, present the weather report clearly.\",\n",
        "    tools=[get_weather], # Pass the function directly\n",
        ")\n",
        "\n",
        "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
      ],
      "metadata": {
        "id": "6Ho1COmKSUeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66cb575-6c7d-49c3-bf4c-81f4246f05b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_v1' created using model 'gemini-2.0-flash-exp'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 3 \\.Configurar corredor y servicio de sesión **\n",
        "\n",
        "Para administrar conversaciones y ejecutar el agente, necesitamos dos componentes más:\n",
        "\n",
        "* `SessionService`: responsable de administrar el historial de conversación y el estado para diferentes usuarios y sesiones.El 'InMemorySessionService' es una implementación simple que almacena todo en la memoria, adecuada para pruebas y aplicaciones simples.Realiza un seguimiento de los mensajes intercambiados.Exploraremos más la persistencia del estado en el paso 4 \\.\n",
        "* `Runner`: el motor que orquesta el flujo de interacción.Toma la entrada del usuario, la enruta al agente apropiado, gestiona las llamadas a la LLM y las herramientas basadas en la lógica del agente, maneja las actualizaciones de la sesión a través del `sessionService` y produce eventos que representan el progreso de la interacción."
      ],
      "metadata": {
        "id": "Dvz7LDhbSZxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Configuración de servicio de sesión y corredor\n",
        "\n",
        "# --- Gestión de la sesión ---\n",
        "# Concepto clave: SessionService Stores Historia y estado de conversación.\n",
        "# InMemorySessionService es un almacenamiento simple y no persistente para este tutorial.\n",
        "session_service = InMemorySessionService()\n",
        "\n",
        "# Definir constantes para identificar el contexto de interacción\n",
        "APP_NAME = \"weather_tutorial_app\"\n",
        "USER_ID = \"user_1\"\n",
        "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
        "\n",
        "# Cree la sesión específica donde sucederá la conversación\n",
        "session = session_service.create_session(\n",
        "    app_name=APP_NAME,\n",
        "    user_id=USER_ID,\n",
        "    session_id=SESSION_ID\n",
        ")\n",
        "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "\n",
        "# --- Runner ---\n",
        "# Concepto clave: Runner orquesta el bucle de ejecución del agente.\n",
        "runner = Runner(\n",
        "    agent=weather_agent, # The agent we want to run\n",
        "    app_name=APP_NAME,   # Associates runs with our app\n",
        "    session_service=session_service # Uses our session manager\n",
        ")\n",
        "print(f\"Runner created for agent '{runner.agent.name}'.\")"
      ],
      "metadata": {
        "id": "h30dNtqMSah5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a301ab6-a79c-417c-d0a5-5cc600549879"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
            "Runner created for agent 'weather_agent_v1'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 4 \\.Interactuar con el agente **\n",
        "\n",
        "Necesitamos una forma de enviar mensajes a nuestro agente y recibir sus respuestas.Dado que las llamadas de LLM y las ejecuciones de herramientas pueden llevar tiempo, el 'Runner` de ADK funciona de manera asincrónica.\n",
        "\n",
        "Definiremos una función de `` async` aelper (`call_agent_async`) que:\n",
        "\n",
        "1. Toma una cadena de consulta de usuario.\n",
        "2. Lo empaqueta en el formato ADK `Content`.\n",
        "3. Llama a `Runner.run_async`, proporcionando el contexto del usuario/sesión y el nuevo mensaje.\n",
        "4. Itera a través de los ** eventos ** cedidos por el corredor.Los eventos representan pasos en la ejecución del agente (por ejemplo, llamada de herramienta solicitada, resultado de la herramienta recibido, pensamiento intermedio de LLM, respuesta final).\n",
        "5. Identifica e imprime la respuesta final ** ** Evento usando `event.is_final_esponse ()`.\n",
        "\n",
        "** ¿Por qué `async`? ** Las interacciones con LLM y potencialmente herramientas (como las API externos) son operaciones de E/S.El uso de `Asyncio` permite que el programa maneje estas operaciones de manera eficiente sin bloquear la ejecución."
      ],
      "metadata": {
        "id": "5zKGVwRkSduA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Definir la función de interacción del agente\n",
        "\n",
        "from google.genai import types # For creating message Content/Parts\n",
        "\n",
        "async def call_agent_async(query: str, runner, user_id, session_id):\n",
        "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
        "  print(f\"\\n>>> User Query: {query}\")\n",
        "\n",
        "# # Prepare el mensaje del usuario en formato ADK\n",
        "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
        "\n",
        "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
        "\n",
        "# # Concepto de clave: Run_async ejecuta la lógica del agente y produce eventos.\n",
        "# # Nos iteramos a través de eventos para encontrar la respuesta final.\n",
        "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
        "# # Puede desenchufar la línea a continuación para ver * todos * eventos durante la ejecución\n",
        "# # print (f \"[evento] autor: {event.author}, type: {type (evento) .__ name__}, final: {event.is_final_esponse ()}, content: {event.content}\")\n",
        "\n",
        "# # Concepto de clave: IS_Final_Response () marca el mensaje final para el giro.\n",
        "      if event.is_final_response():\n",
        "          if event.content and event.content.parts:\n",
        "# # Suponiendo la respuesta de texto en la primera parte\n",
        "             final_response_text = event.content.parts[0].text\n",
        "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
        "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
        "# # Agregue más cheques aquí si es necesario (por ejemplo, códigos de error específicos)\n",
        "          break # Stop processing events once the final response is found\n",
        "\n",
        "  print(f\"<<< Agent Response: {final_response_text}\")"
      ],
      "metadata": {
        "id": "yZJr8lbkSebH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 5 \\.Ejecutar la conversación **\n",
        "\n",
        "Finalmente, probemos nuestra configuración enviando algunas consultas al agente.Envolvemos nuestras llamadas `Async` en una función principal` Async` y la ejecutamos usando `esperanza '.\n",
        "\n",
        "Mira la salida:\n",
        "\n",
        "* Ver las consultas de usuario.\n",
        "* Observe la herramienta `---: get_weather llamada ... ---` registra cuando el agente usa la herramienta.\n",
        "* Observe las respuestas finales del agente, incluida la forma en que maneja el caso donde los datos meteorológicos no están disponibles (para París)."
      ],
      "metadata": {
        "id": "Z6DQSqrqk5ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Ejecute la conversación inicial\n",
        "\n",
        "# Necesitamos una función asíncrata para esperar a nuestro ayudante de interacción\n",
        "async def run_conversation():\n",
        "    await call_agent_async(\"What is the weather like in London?\",\n",
        "                                       runner=runner,\n",
        "                                       user_id=USER_ID,\n",
        "                                       session_id=SESSION_ID)\n",
        "\n",
        "    await call_agent_async(\"How about Paris?\",\n",
        "                                       runner=runner,\n",
        "                                       user_id=USER_ID,\n",
        "                                       session_id=SESSION_ID) # Expecting the tool's error message\n",
        "\n",
        "    await call_agent_async(\"Tell me the weather in New York\",\n",
        "                                       runner=runner,\n",
        "                                       user_id=USER_ID,\n",
        "                                       session_id=SESSION_ID)\n",
        "\n",
        "# Ejecute la conversación usando espera en un contexto de asíncrono (como Colab/Jupyter)\n",
        "await run_conversation()"
      ],
      "metadata": {
        "id": "mEd2QhHyUKY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d136daca-c821-4796-f25b-135ce40471cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> User Query: What is the weather like in London?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: London ---\n",
            "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
            "\n",
            "\n",
            ">>> User Query: How about Paris?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: Paris ---\n",
            "<<< Agent Response: I am sorry, I don't have weather information for Paris.\n",
            "\n",
            "\n",
            ">>> User Query: Tell me the weather in New York\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: New York ---\n",
            "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Felicidades\\!Ha construido e interactuado con éxito con su primer agente de ADK.Entiende la solicitud del usuario, utiliza una herramienta para encontrar información y responde adecuadamente en función del resultado de la herramienta.\n",
        "\n",
        "En el siguiente paso, exploraremos cómo cambiar fácilmente el modelo de lenguaje subyacente que alimenta a este agente."
      ],
      "metadata": {
        "id": "xbUzAGvsmB2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Ir múltiples modelos con litellm\n",
        "\n",
        "En el paso 1, construimos un agente meteorológico funcional impulsado por un modelo de Géminis específico.Si bien son efectivas, las aplicaciones del mundo real a menudo se benefician de la flexibilidad para usar * diferentes * modelos de lenguaje grande (LLM).¿Por qué?\n",
        "\n",
        "*** Rendimiento: ** Algunos modelos se destacan en tareas específicas (por ejemplo, codificación, razonamiento, escritura creativa).\n",
        "*** Costo: ** Los diferentes modelos tienen puntos de precio variables.\n",
        "*** Capacidades: ** Los modelos ofrecen características diversas, tamaños de ventana de contexto y opciones de ajuste fino.\n",
        "*** Disponibilidad/redundancia: ** Tener alternativas asegura que su aplicación permanezca funcional incluso si un proveedor experimenta problemas.\n",
        "\n",
        "ADK hace que el cambio entre modelos sea sin costuras a través de su integración con la biblioteca [** litellm **] (https://github.com/berriai/litellm).Litellm actúa como una interfaz consistente para más de 100 LLM diferentes.\n",
        "\n",
        "** En este paso, lo haremos: **\n",
        "\n",
        "1. Aprenda a configurar un ADK `agente` para usar modelos de proveedores como OpenAI (GPT) y Anthrope (Claude) utilizando el envoltorio 'litellm`.\n",
        "2. Definir, configurar (con sus propias sesiones y corredores), e inmediatamente pruebe las instancias de nuestro agente meteorológico, cada uno respaldado por un LLM diferente.\n",
        "3. Interactuar con estos diferentes agentes para observar variaciones potenciales en sus respuestas, incluso cuando se usa la misma herramienta subyacente."
      ],
      "metadata": {
        "id": "HEPaI-beSh8P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 1 \\.Importar `litellm` **\n",
        "\n",
        "Importamos esto durante la configuración inicial (Paso 0), pero es el componente clave para el soporte de múltiples modelos:"
      ],
      "metadata": {
        "id": "OvfhdrCDnPMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 1. Importar litellm\n",
        "from google.adk.models.lite_llm import LiteLlm"
      ],
      "metadata": {
        "id": "mPBr56NSnMje"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** 2 \\.Definir y probar agentes multimodelo **\n",
        "\n",
        "En lugar de pasar solo una cadena de nombre del modelo (que es predeterminada a los modelos Gemini de Google), envolvemos la cadena de identificador del modelo deseada dentro de la clase 'litellm`.\n",
        "\n",
        "*** Concepto clave: `litellm` Wrapper: ** El` litellm (model = \"proveedor/model_name\") `La sintaxis le dice a ADK que enrute las solicitudes de este agente a través de la biblioteca litellm al proveedor de modelos especificado.\n",
        "\n",
        "Asegúrese de haber configurado las claves API necesarias para OpenAI y Anthrope en el paso 0. Usaremos la función `Call_agent_async` (definida anteriormente, que ahora acepta` Runner`, `User_id` y` session_id`) para interactuar con cada agente inmediatamente después de su configuración.\n",
        "\n",
        "Cada bloque a continuación será:\n",
        "* Defina el agente utilizando un modelo litellm específico (`model_gpt_4o` o` model_claude_sonnet`).\n",
        "* Cree un * nuevo, separado * `InMemorySessionService` y Session específicamente para la ejecución de la prueba de ese agente.Esto mantiene las historias de conversación aisladas para esta demostración.\n",
        "* Cree un `Runner` configurado para el agente específico y su servicio de sesión.\n",
        "* Llame inmediatamente a `call_agent_async` para enviar una consulta y probar el agente.\n",
        "\n",
        "** Las mejores prácticas: ** Use constantes para nombres de modelos (como `model_gpt_4o`,` model_claude_sonnet` definido en el paso 0) para evitar errores tipográficos y facilitar el código de administrar.\n",
        "\n",
        "** Manejo de errores: ** Envolvemos las definiciones del agente en `intento ... excepto 'bloques.Esto evita que la celda de código completa falle si falta una clave API para un proveedor específico o no es válido, lo que permite que el tutorial continúe con los modelos que * están * configurados.\n",
        "\n",
        "Primero, creemos y probemos el agente usando el GPT-4O de OpenAI."
      ],
      "metadata": {
        "id": "NoUbe1mZnXd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# title Define and Test GPT Agent\n",
        "\n",
        "# Asegúrese de que la función 'get_weather' del paso 1 se define en su entorno.\n",
        "# Asegúrese de que 'call_agent_async' se define desde anteriormente.\n",
        "\n",
        "# --- Agente usando GPT-4O ---\n",
        "weather_agent_gpt = None # Initialize to None\n",
        "runner_gpt = None      # Initialize runner to None\n",
        "\n",
        "try:\n",
        "    weather_agent_gpt = Agent(\n",
        "        name=\"weather_agent_gpt\",\n",
        "# # Cambio de teclas: envuelva el identificador del modelo litellm\n",
        "        model=LiteLlm(model=MODEL_GPT_4O),\n",
        "        description=\"Provides weather information (using GPT-4o).\",\n",
        "        instruction=\"You are a helpful weather assistant powered by GPT-4o. \"\n",
        "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
        "                    \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n",
        "        tools=[get_weather], # Re-use the same tool\n",
        "    )\n",
        "    print(f\"Agent '{weather_agent_gpt.name}' created using model '{MODEL_GPT_4O}'.\")\n",
        "\n",
        "# # InMemorySessionService es un almacenamiento simple y no persistente para este tutorial.\n",
        "    session_service_gpt = InMemorySessionService() # Create a dedicated service\n",
        "\n",
        "# # Definir constantes para identificar el contexto de interacción\n",
        "    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test\n",
        "    USER_ID_GPT = \"user_1_gpt\"\n",
        "    SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity\n",
        "\n",
        "# # Crea la sesión específica donde sucederá la conversación\n",
        "    session_gpt = session_service_gpt.create_session(\n",
        "        app_name=APP_NAME_GPT,\n",
        "        user_id=USER_ID_GPT,\n",
        "        session_id=SESSION_ID_GPT\n",
        "    )\n",
        "    print(f\"Session created: App='{APP_NAME_GPT}', User='{USER_ID_GPT}', Session='{SESSION_ID_GPT}'\")\n",
        "\n",
        "# # Crear un corredor específico para este agente y su servicio de sesión\n",
        "    runner_gpt = Runner(\n",
        "        agent=weather_agent_gpt,\n",
        "        app_name=APP_NAME_GPT,       # Use the specific app name\n",
        "        session_service=session_service_gpt # Use the specific session service\n",
        "        )\n",
        "    print(f\"Runner created for agent '{runner_gpt.agent.name}'.\")\n",
        "\n",
        "    # --- Test the GPT Agent ---\n",
        "    print(\"\\n--- Testing GPT Agent ---\")\n",
        "# # Asegúrese de que Call_agent_async use el corredor correcto, user_id, session_id\n",
        "    await call_agent_async(query = \"What's the weather in Tokyo?\",\n",
        "                           runner=runner_gpt,\n",
        "                           user_id=USER_ID_GPT,\n",
        "                           session_id=SESSION_ID_GPT)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create or run GPT agent '{MODEL_GPT_4O}'. Check API Key and model name. Error: {e}\")\n"
      ],
      "metadata": {
        "id": "C2WvKj4_Sp2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1c8052-0706-4ab4-ab22-a597c8de47ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_gpt' created using model 'openai/gpt-4o-mini'.\n",
            "Session created: App='weather_tutorial_app_gpt', User='user_1_gpt', Session='session_001_gpt'\n",
            "Runner created for agent 'weather_agent_gpt'.\n",
            "\n",
            "--- Testing GPT Agent ---\n",
            "\n",
            ">>> User Query: What's the weather in Tokyo?\n",
            "--- Tool: get_weather called for city: Tokyo ---\n",
            "<<< Agent Response: The weather in Tokyo is currently light rain with a temperature of 18°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, haremos lo mismo por el soneto Claude de Anthrope."
      ],
      "metadata": {
        "id": "Gu_OHirKWFXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Definir y probar el agente de Claude\n",
        "\n",
        "# Asegúrese de que la función 'get_weather' del paso 1 se define en su entorno.\n",
        "# Asegúrese de que 'call_agent_async' se define desde anteriormente.\n",
        "\n",
        "# --- Agente usando el soneto de Claude ---\n",
        "weather_agent_claude = None # Initialize to None\n",
        "runner_claude = None      # Initialize runner to None\n",
        "\n",
        "try:\n",
        "    weather_agent_claude = Agent(\n",
        "        name=\"weather_agent_claude\",\n",
        "# # Cambio de teclas: envuelva el identificador del modelo litellm\n",
        "        model=LiteLlm(model=MODEL_CLAUDE_SONNET),\n",
        "        description=\"Provides weather information (using Claude Sonnet).\",\n",
        "        instruction=\"You are a helpful weather assistant powered by Claude Sonnet. \"\n",
        "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
        "                    \"Analyze the tool's dictionary output ('status', 'report'/'error_message'). \"\n",
        "                    \"Clearly present successful reports or polite error messages.\",\n",
        "        tools=[get_weather], # Re-use the same tool\n",
        "    )\n",
        "    print(f\"Agent '{weather_agent_claude.name}' created using model '{MODEL_CLAUDE_SONNET}'.\")\n",
        "\n",
        "# # InMemorySessionService es un almacenamiento simple y no persistente para este tutorial.\n",
        "    session_service_claude = InMemorySessionService() # Create a dedicated service\n",
        "\n",
        "# # Definir constantes para identificar el contexto de interacción\n",
        "    APP_NAME_CLAUDE = \"weather_tutorial_app_claude\" # Unique app name\n",
        "    USER_ID_CLAUDE = \"user_1_claude\"\n",
        "    SESSION_ID_CLAUDE = \"session_001_claude\" # Using a fixed ID for simplicity\n",
        "\n",
        "# # Crea la sesión específica donde sucederá la conversación\n",
        "    session_claude = session_service_claude.create_session(\n",
        "        app_name=APP_NAME_CLAUDE,\n",
        "        user_id=USER_ID_CLAUDE,\n",
        "        session_id=SESSION_ID_CLAUDE\n",
        "    )\n",
        "    print(f\"Session created: App='{APP_NAME_CLAUDE}', User='{USER_ID_CLAUDE}', Session='{SESSION_ID_CLAUDE}'\")\n",
        "\n",
        "# # Crear un corredor específico para este agente y su servicio de sesión\n",
        "    runner_claude = Runner(\n",
        "        agent=weather_agent_claude,\n",
        "        app_name=APP_NAME_CLAUDE,       # Use the specific app name\n",
        "        session_service=session_service_claude # Use the specific session service\n",
        "        )\n",
        "    print(f\"Runner created for agent '{runner_claude.agent.name}'.\")\n",
        "\n",
        "# # --- Prueba el agente de Claude ---\n",
        "    print(\"\\n--- Testing Claude Agent ---\")\n",
        "# # Asegúrese de que Call_agent_async use el corredor correcto, user_id, session_id\n",
        "    await call_agent_async(query = \"Weather in London please.\",\n",
        "                           runner=runner_claude,\n",
        "                           user_id=USER_ID_CLAUDE,\n",
        "                           session_id=SESSION_ID_CLAUDE)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create or run Claude agent '{MODEL_CLAUDE_SONNET}'. Check API Key and model name. Error: {e}\")"
      ],
      "metadata": {
        "id": "7zqJIS4_nhoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e2daa9-df75-4bef-f975-24b4bedf306b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 'weather_agent_claude' created using model 'anthropic/claude-3-sonnet-20240229'.\n",
            "Session created: App='weather_tutorial_app_claude', User='user_1_claude', Session='session_001_claude'\n",
            "Runner created for agent 'weather_agent_claude'.\n",
            "\n",
            "--- Testing Claude Agent ---\n",
            "\n",
            ">>> User Query: Weather in London please.\n",
            "--- Tool: get_weather called for city: London ---\n",
            "<<< Agent Response: The weather report for London is:\n",
            "\n",
            "It's cloudy in London with a temperature of 15°C.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe la salida cuidadosamente desde ambos bloques de código.Deberías ver:\n",
        "\n",
        "1. Cada agente (`Weather_agent_gpt`,` Weather_agent_claude`) se crea con éxito (si las teclas API son válidas).\n",
        "2. Una sesión dedicada y un corredor están configurados para cada uno.\n",
        "3. Cada agente identifica correctamente la necesidad de usar la herramienta `get_weather` al procesar la consulta (verá la herramienta` ---: get_weather llamada ... --- `log).\n",
        "4. La lógica de la herramienta * subyacente * sigue siendo idéntica, siempre devuelve nuestros datos simulados.\n",
        "5. Sin embargo, la respuesta textual final ** generada por cada agente podría diferir ligeramente en el fraseo, tono o formato.Esto se debe a que el mensaje de instrucción es interpretado y ejecutado por diferentes LLM (GPT-4O vs. Claude sonnet).\n",
        "\n",
        "Este paso demuestra la potencia y la flexibilidad de ADK + litellm.Puede experimentar e implementar fácilmente agentes utilizando varios LLM mientras mantiene consistente su lógica de aplicación central (herramientas, estructura de agentes fundamentales).\n",
        "\n",
        "¡En el siguiente paso, iremos más allá de un solo agente y construiremos un equipo pequeño donde los agentes puedan delegar tareas entre sí!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "xsroj8NzWMU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: Construyendo un equipo de agente \\- Delegación para saludos y despedidas\n",
        "\n",
        "En los pasos 1 y 2, construimos y experimentamos con un solo agente enfocado únicamente en las búsquedas meteorológicas.Si bien es efectivo para su tarea específica, las aplicaciones del mundo real a menudo implican manejar una variedad más amplia de interacciones de usuario.* Podríamos * seguir agregando más herramientas e instrucciones complejas a nuestro agente meteorológico único, pero esto puede volverse inmanejable y menos eficiente.\n",
        "\n",
        "Un enfoque más robusto es construir un ** equipo de agente **.Esto implica:\n",
        "\n",
        "1. Creación de múltiples agentes especializados **, cada uno diseñado para una capacidad específica (por ejemplo, uno para clima, uno para saludos, uno para cálculos).\n",
        "2. Designando un agente raíz ** ** (o orquestador) que recibe la solicitud inicial del usuario.\n",
        "3. Habilitar al agente raíz para ** Delegar ** La solicitud al sub-agente especializado más apropiado en función de la intención del usuario.\n",
        "\n",
        "** ¿Por qué construir un equipo de agente? **\n",
        "\n",
        "*** Modularidad: ** Más fácil de desarrollar, probar y mantener agentes individuales.\n",
        "*** Especialización: ** Cada agente se puede ajustar (instrucciones, elección del modelo) para su tarea específica.\n",
        "*** Escalabilidad: ** Más simple agregar nuevas capacidades agregando nuevos agentes.\n",
        "*** Eficiencia: ** Permite usar modelos potencialmente más simples/más baratos para tareas más simples (como saludos).\n",
        "\n",
        "** En este paso, lo haremos: **\n",
        "\n",
        "1. Defina herramientas simples para manejar saludos (`say_hello`) y despedidas (` say_goodbye`).\n",
        "2. Cree dos nuevos sub-agentes especializados: `Saluding_agent` y` Farewell_agent`.\n",
        "3. Actualice nuestro agente meteorológico principal (`Weather_Agent_V2`) para actuar como el ** Root Agent **.\n",
        "4. Configure el agente raíz con sus subcásgenes, habilitando ** la delegación automática **.\n",
        "5. Pruebe el flujo de delegación enviando diferentes tipos de solicitudes al agente raíz."
      ],
      "metadata": {
        "id": "tL5estZ_VKki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 1 \\.Definir herramientas para sub-agentes **\n",
        "\n",
        "Primero, creemos las funciones simples de Python que servirán como herramientas para nuestros nuevos agentes especializados.Recuerde, las documentos claros son vitales para los agentes que los usarán."
      ],
      "metadata": {
        "id": "tLpXYXxppB4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Definir herramientas para agentes de saludo y despedida\n",
        "\n",
        "# Asegúrese de que 'get_weather' del paso 1 esté disponible si ejecuta este paso de forma independiente.\n",
        "# Def get_weather (ciudad: str) -> dict: ... (del paso 1)\n",
        "\n",
        "def say_hello(name: str = \"there\") -> str:\n",
        "    \"\"\"Provides a simple greeting, optionally addressing the user by name.\n",
        "\n",
        "    Args:\n",
        "        name (str, optional): The name of the person to greet. Defaults to \"there\".\n",
        "\n",
        "    Returns:\n",
        "        str: A friendly greeting message.\n",
        "    \"\"\"\n",
        "    print(f\"--- Tool: say_hello called with name: {name} ---\")\n",
        "    return f\"Hello, {name}!\"\n",
        "\n",
        "def say_goodbye() -> str:\n",
        "    \"\"\"Provides a simple farewell message to conclude the conversation.\"\"\"\n",
        "    print(f\"--- Tool: say_goodbye called ---\")\n",
        "    return \"Goodbye! Have a great day.\"\n",
        "\n",
        "print(\"Greeting and Farewell tools defined.\")\n",
        "\n",
        "# Testimas de autocomprobación opcional\n",
        "print(say_hello(\"Alice\"))\n",
        "print(say_goodbye())"
      ],
      "metadata": {
        "id": "Qc7dHr4ZVM6X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb3ac0e1-95da-4621-92d5-4d4ac5647d5e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greeting and Farewell tools defined.\n",
            "--- Tool: say_hello called with name: Alice ---\n",
            "Hello, Alice!\n",
            "--- Tool: say_goodbye called ---\n",
            "Goodbye! Have a great day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 2 \\.Definir los sub-agentes (saludo y despedida) **\n",
        "\n",
        "Ahora, cree las instancias de `agente` para nuestros especialistas.Observe su 'instrucción' altamente enfocada y, críticamente, su clara 'descripción'.La `descripción` es la información principal que * Root Agent * usa para decidir * cuando * delegar a estos subcacios.\n",
        "\n",
        "¡Incluso podemos usar diferentes LLM para estos subgestados \\!Asignemos GPT-4O al agente de saludo y mantengamos al agente de despedida usando GPT-4O también (podría cambiar fácilmente uno a Claude o Gemini si lo desea y las teclas API están establecidas).\n",
        "\n",
        "** Las mejores prácticas: ** Los campos de `descripción` sub-agentes deben resumir de manera precisa y concisa su capacidad específica.Esto es crucial para una delegación automática efectiva.\n",
        "\n",
        "** Las mejores prácticas: ** Los campos de `instrucciones` sub-agentes deben adaptarse a su alcance limitado, diciéndoles exactamente qué hacer y*qué no*hacer (por ejemplo,\" Su*solo*tarea es ... \")."
      ],
      "metadata": {
        "id": "lkv34_tMVPG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Defina sub-agentes de saludo y despedida\n",
        "\n",
        "# Asegúrese de que se importe litellm y las teclas API se establezcan (desde el paso 0/2)\n",
        "# de google.adk.models.lite_llm import litellm\n",
        "# Model_gpt_4o, model_claude_sonnet, etc. debe definirse\n",
        "\n",
        "# --- Agente de saludo ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    greeting_agent = Agent(\n",
        "# Uso de un modelo potencialmente diferente/más barato para una tarea simple\n",
        "        model=LiteLlm(model=MODEL_GPT_4O),\n",
        "        name=\"greeting_agent\",\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting to the user. \"\n",
        "                    \"Use the 'say_hello' tool to generate the greeting. \"\n",
        "                    \"If the user provides their name, make sure to pass it to the tool. \"\n",
        "                    \"Do not engage in any other conversation or tasks.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\", # Crucial for delegation\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Agent '{greeting_agent.name}' created using model '{MODEL_GPT_4O}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create Greeting agent. Check API Key ({MODEL_GPT_4O}). Error: {e}\")\n",
        "\n",
        "# --- Agente de despedida ---\n",
        "farewell_agent = None\n",
        "try:\n",
        "    farewell_agent = Agent(\n",
        "# Puede usar el mismo modelo o un modelo diferente\n",
        "        model=LiteLlm(model=MODEL_GPT_4O), # Sticking with GPT for this example\n",
        "        name=\"farewell_agent\",\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message. \"\n",
        "                    \"Use the 'say_goodbye' tool when the user indicates they are leaving or ending the conversation \"\n",
        "                    \"(e.g., using words like 'bye', 'goodbye', 'thanks bye', 'see you'). \"\n",
        "                    \"Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\", # Crucial for delegation\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Agent '{farewell_agent.name}' created using model '{MODEL_GPT_4O}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not create Farewell agent. Check API Key ({MODEL_GPT_4O}). Error: {e}\")"
      ],
      "metadata": {
        "id": "tgT7P1doVRA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16985838-b3d1-43fb-9609-ed7d8351d8c5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent 'greeting_agent' created using model 'openai/gpt-4o-mini'.\n",
            "✅ Agent 'farewell_agent' created using model 'openai/gpt-4o-mini'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 3 \\.Defina el agente raíz (agente meteorológico v2) con sub-agentes **\n",
        "\n",
        "Ahora, actualizamos nuestro `Weather_agent`.Los cambios clave son:\n",
        "\n",
        "* Agregar el parámetro `sub_agents`: pasamos una lista que contiene las instancias` Saluding_Agent` y `Farewell_agent` que acabamos de crear.\n",
        "* Actualización de la `instrucción`: le decimos explícitamente al agente raíz * sobre * sus sub-agentes y * cuando * debe delegarles tareas.\n",
        "\n",
        "** Concepto clave: Delegación automática (flujo automático) ** Al proporcionar la lista de `sub_agents ', ADK habilita la delegación automática.Cuando el agente raíz recibe una consulta de usuario, su LLM considera no solo sus propias instrucciones y herramientas sino también la 'descripción' de cada subgent.Si el LLM determina que una consulta se alinea mejor con la capacidad descrita de un subgente (por ejemplo, \"maneja saludos simples\"), generará automáticamente una acción interna especial para * transferir control * a ese subgent para ese turno.El subagente luego procesa la consulta utilizando su propio modelo, instrucciones y herramientas.\n",
        "\n",
        "** Las mejores prácticas: ** Asegúrese de que las instrucciones del agente raíz guíen claramente sus decisiones de delegación.Mencione los subgestados por nombre y describa las condiciones bajo las cuales debe ocurrir la delegación."
      ],
      "metadata": {
        "id": "IFL_TLFPVS5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title Defina el agente raíz con los subcásgenes\n",
        "\n",
        "# Asegúrese de que los subgestados se creen con éxito antes de definir el agente raíz.\n",
        "# También asegúrese de definir la herramienta original 'get_weather'.\n",
        "root_agent = None\n",
        "runner_root = None # Initialize runner\n",
        "\n",
        "if greeting_agent and farewell_agent and 'get_weather' in globals():\n",
        "# # Usemos un modelo Géminis capaz para que el agente de la raíz maneje la orquestación\n",
        "    root_agent_model = MODEL_GEMINI_2_0_FLASH\n",
        "\n",
        "    weather_agent_team = Agent(\n",
        "        name=\"weather_agent_v2\", # Give it a new version name\n",
        "        model=root_agent_model,\n",
        "        description=\"The main coordinator agent. Handles weather requests and delegates greetings/farewells to specialists.\",\n",
        "        instruction=\"You are the main Weather Agent coordinating a team. Your primary responsibility is to provide weather information. \"\n",
        "                    \"Use the 'get_weather' tool ONLY for specific weather requests (e.g., 'weather in London'). \"\n",
        "                    \"You have specialized sub-agents: \"\n",
        "                    \"1. 'greeting_agent': Handles simple greetings like 'Hi', 'Hello'. Delegate to it for these. \"\n",
        "                    \"2. 'farewell_agent': Handles simple farewells like 'Bye', 'See you'. Delegate to it for these. \"\n",
        "                    \"Analyze the user's query. If it's a greeting, delegate to 'greeting_agent'. If it's a farewell, delegate to 'farewell_agent'. \"\n",
        "                    \"If it's a weather request, handle it yourself using 'get_weather'. \"\n",
        "                    \"For anything else, respond appropriately or state you cannot handle it.\",\n",
        "        tools=[get_weather], # Root agent still needs the weather tool for its core task\n",
        "# # Cambio de teclas: ¡Enlace los sub-agentes aquí!\n",
        "        sub_agents=[greeting_agent, farewell_agent]\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{weather_agent_team.name}' created using model '{root_agent_model}' with sub-agents: {[sa.name for sa in weather_agent_team.sub_agents]}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create root agent because one or more sub-agents failed to initialize or 'get_weather' tool is missing.\")\n",
        "    if not greeting_agent: print(\" - Greeting Agent is missing.\")\n",
        "    if not farewell_agent: print(\" - Farewell Agent is missing.\")\n",
        "    if 'get_weather' not in globals(): print(\" - get_weather function is missing.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nniWunchVV8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca87988-e689-43a7-f163-d4642f75d5c0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Root Agent 'weather_agent_v2' created using model 'gemini-2.0-flash-exp' with sub-agents: ['greeting_agent', 'farewell_agent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 4 \\.Interactuar con el equipo del agente **\n",
        "\n",
        "Ahora que hemos definido nuestro agente raíz (`weather_agent_team`- *Nota: Asegúrese de que este nombre de variable coincida con el definido en el bloque de código anterior, probablemente`# @title defina el agente raíz con los subgentadores ', que podría haberlo nombrado `root_agent` *) con sus sub-agentes especializados, prueba el mecanismo de delegación.\n",
        "\n",
        "El siguiente bloque de código:\n",
        "\n",
        "1. Defina una función `async`` run_team_conversation`.\n",
        "2. Dentro de esta función, cree un * nuevo y dedicado * `InMemorySessionService` y una sesión específica (` session_001_agent_team`) solo para esta ejecución de prueba.Esto aísla el historial de conversación para probar la dinámica del equipo.\n",
        "3. Cree un `Runner` (` Runner_agent_Team`) configurado para usar nuestro 'Weather_agent_Team` (el agente raíz) y el servicio de sesión dedicado.\n",
        "4. Use nuestra función actualizada de `call_agent_async` para enviar diferentes tipos de consultas (saludo, solicitud de clima, despedida) al 'runner_agent_team`.Pasamos explícitamente el corredor, ID de usuario y ID de sesión para esta prueba específica.\n",
        "5. Ejecute inmediatamente la función `run_team_conversation`.\n",
        "\n",
        "Esperamos el siguiente flujo:\n",
        "\n",
        "1. El \"¡Hola!\"La consulta va a `RUNNER_AGENT_TEAM`.\n",
        "2. El agente raíz (`weather_agent_team`) lo recibe y, según sus instrucciones y la descripción de` saludo_agent`, delega la tarea.\n",
        "3. `Saluding_Agent` maneja la consulta, llama a su herramienta` say_hello` y genera la respuesta.\n",
        "4. El \"¿Cuál es el clima en Nueva York?\"La consulta es * no * delegada y es manejada directamente por el agente raíz utilizando su herramienta 'get_weather`.\n",
        "5. El \"¡Gracias, adiós!\"La consulta se delega a la `Farwell_agent`, que utiliza su herramienta 'say_goodbye`."
      ],
      "metadata": {
        "id": "Yg-IjZYVVYXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title interactúa con el equipo de agentes\n",
        "\n",
        "# Asegúrese de que se define el agente raíz (por ejemplo, 'weather_agent_team' o 'root_agent' de la celda anterior).\n",
        "# Asegúrese de definir la función Call_agent_async.\n",
        "\n",
        "# Compruebe si la variable de agente raíz existe antes de definir la función de conversación\n",
        "root_agent_var_name = 'root_agent' # Default name from Step 3 guide\n",
        "if 'weather_agent_team' in globals(): # Check if user used this name instead\n",
        "    root_agent_var_name = 'weather_agent_team'\n",
        "elif 'root_agent' not in globals():\n",
        "    print(\"⚠️ Root agent ('root_agent' or 'weather_agent_team') not found. Cannot define run_team_conversation.\")\n",
        "# # Asigne un valor ficticio para evitar NameError más tarde si el bloque de código se ejecuta de todos modos\n",
        "    root_agent = None\n",
        "\n",
        "if root_agent_var_name in globals() and globals()[root_agent_var_name]:\n",
        "    async def run_team_conversation():\n",
        "        print(\"\\n--- Testing Agent Team Delegation ---\")\n",
        "# # InMemorySessionService es un almacenamiento simple y no persistente para este tutorial.\n",
        "        session_service = InMemorySessionService()\n",
        "\n",
        "# # Definir constantes para identificar el contexto de interacción\n",
        "        APP_NAME = \"weather_tutorial_agent_team\"\n",
        "        USER_ID = \"user_1_agent_team\"\n",
        "        SESSION_ID = \"session_001_agent_team\" # Using a fixed ID for simplicity\n",
        "\n",
        "# # Crea la sesión específica donde sucederá la conversación\n",
        "        session = session_service.create_session(\n",
        "            app_name=APP_NAME,\n",
        "            user_id=USER_ID,\n",
        "            session_id=SESSION_ID\n",
        "        )\n",
        "        print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
        "\n",
        "# # --- Obtenga el objeto de agente raíz real ---\n",
        "# # Use el nombre de la variable determinado\n",
        "        actual_root_agent = globals()[root_agent_var_name]\n",
        "\n",
        "# # Crear un corredor específico para esta prueba de equipo de agente\n",
        "        runner_agent_team = Runner(\n",
        "            agent=actual_root_agent, # Use the root agent object\n",
        "            app_name=APP_NAME,       # Use the specific app name\n",
        "            session_service=session_service # Use the specific session service\n",
        "            )\n",
        "# # Declaración de impresión corregida para mostrar el nombre del agente raíz real\n",
        "        print(f\"Runner created for agent '{actual_root_agent.name}'.\")\n",
        "\n",
        "# # Siempre interactúa a través del corredor del agente raíz, pasando las identificaciones correctas\n",
        "        await call_agent_async(query = \"Hello there!\",\n",
        "                               runner=runner_agent_team,\n",
        "                               user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "        await call_agent_async(query = \"What is the weather in New York?\",\n",
        "                               runner=runner_agent_team,\n",
        "                               user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "        await call_agent_async(query = \"Thanks, bye!\",\n",
        "                               runner=runner_agent_team,\n",
        "                               user_id=USER_ID,\n",
        "                               session_id=SESSION_ID)\n",
        "\n",
        "# # Ejecutar la conversación\n",
        "# # NOTA: ¡Esto puede requerir claves API para los modelos utilizados por la raíz y los subcibentes!\n",
        "    await run_team_conversation()\n",
        "else:\n",
        "    print(\"\\n⚠️ Skipping agent team conversation as the root agent was not successfully defined in the previous step.\")\n"
      ],
      "metadata": {
        "id": "t9Wy4ai8VZ7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efebf1c3-1b04-4f6e-ffba-af2b0621c00d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Agent Team Delegation ---\n",
            "Session created: App='weather_tutorial_agent_team', User='user_1_agent_team', Session='session_001_agent_team'\n",
            "Runner created for agent 'weather_agent_v2'.\n",
            "\n",
            ">>> User Query: Hello there!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n",
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n",
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: say_hello called with name: there ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<< Agent Response: Hello, there!\n",
            "\n",
            ">>> User Query: What is the weather in New York?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: New York ---\n",
            "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
            "\n",
            "\n",
            ">>> User Query: Thanks, bye!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: say_goodbye called ---\n",
            "<<< Agent Response: Goodbye! Have a great day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mire de cerca los registros de salida, especialmente la herramienta `---: ... llamada ---` Mensajes.Deberías observar:\n",
        "\n",
        "* Para \"¡Hola!\", Se llamó a la herramienta `say_hello` (que indica` saludo_agent` lo manejó).\n",
        "* Para \"¿Cuál es el clima en Nueva York?\", Se llamó la herramienta `get_weather` (indicando que el agente raíz lo manejó).\n",
        "* Por \"¡Gracias, adiós!\", Se llamó la herramienta `say_goodbye` (que indica` Farewell_agent` lo manejó).\n",
        "\n",
        "¡Esto confirma la delegación automática exitosa **!El agente raíz, guiado por sus instrucciones y la 'descripción' de su `sub_agents`, enrutó correctamente las solicitudes de usuario al agente especializado apropiado dentro del equipo.\n",
        "\n",
        "Ahora ha estructurado su aplicación con múltiples agentes de colaboración.Este diseño modular es fundamental para construir sistemas de agentes más complejos y capaces.En el siguiente paso, daremos a nuestros agentes la capacidad de recordar información en los giros utilizando el estado de la sesión."
      ],
      "metadata": {
        "id": "Zgw3Cn2NVcI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 4: Agregar memoria y personalización con el estado de sesión\n",
        "\n",
        "Hasta ahora, nuestro equipo de agentes puede manejar diferentes tareas a través de la delegación, pero cada interacción comienza fresca: los agentes no tienen memoria de conversaciones pasadas o preferencias de usuario dentro de una sesión.Para crear experiencias más sofisticadas y conscientes del contexto, los agentes necesitan ** memoria **.ADK proporciona esto a través del estado de la sesión ** **.\n",
        "\n",
        "** ¿Qué es el estado de la sesión? **\n",
        "\n",
        "* Es un Diccionario de Python (`session.state`) vinculado a una sesión de usuario específica (identificada por` app_name`, `user_id`,` session_id`).\n",
        "* Persiste información * en múltiples giros conversacionales * dentro de esa sesión.\n",
        "* Los agentes y herramientas pueden leer y escribir en este estado, lo que les permite recordar detalles, adaptar el comportamiento y personalizar las respuestas.\n",
        "\n",
        "** Cómo los agentes interactúan con el estado: **\n",
        "\n",
        "1. ** `ToolContext` (método primario): ** Las herramientas pueden aceptar un objeto` ToolContext` (proporcionado automáticamente por ADK si se declara como el último argumento).Este objeto brinda acceso directo al estado de sesión a través de `tool_context.state`, permitiendo herramientas para leer las preferencias o guardar resultados * durante * ejecución.\n",
        "2. ** `Output_Key` (respuesta de agente automático): ** Un` agente` se puede configurar con un `output_key =\" your_key \"`.ADK guardará automáticamente la respuesta textual final del agente para convertir un convertido en `session.state [\" your_key \"]`.\n",
        "\n",
        "** En este paso, mejoraremos nuestro equipo de botes meteorológicos por: **\n",
        "\n",
        "1. Uso de un ** nuevo ** `InMemorySessionService` para demostrar el estado de forma aislada.\n",
        "2. Inicialización del estado de la sesión con una preferencia del usuario por `temperatura_unit`.\n",
        "3. Creación de una versión de estado de estado de la herramienta meteorológica (`get_weather_stateful`) que lee esta preferencia a través de` ToolContext` y ajusta su formato de salida (Celsius/Fahrenheit).\n",
        "4. Actualización del agente raíz para usar esta herramienta con estado y configurarla con un `output_key` para guardar automáticamente su informe meteorológico final en el estado de la sesión.\n",
        "5. Ejecutar una conversación para observar cómo el estado inicial afecta la herramienta, cómo los cambios en el estado manual alteran el comportamiento posterior y cómo `` `` `ones persiste '' persiste la respuesta del agente."
      ],
      "metadata": {
        "id": "s7gD2sCy1qWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 1 \\.Inicializar el nuevo servicio de sesión y el estado **\n",
        "\n",
        "Para demostrar claramente la gestión del estado sin interferencia de pasos anteriores, instanciaremos un nuevo 'InMemorySessionService'.También crearemos una sesión con un estado inicial que define la unidad de temperatura preferida del usuario."
      ],
      "metadata": {
        "id": "HsIjxunW1xeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 1. Inicializar un nuevo servicio de sesión y estado\n",
        "\n",
        "# Importar componentes de sesión necesarios\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "\n",
        "# Cree una nueva instancia de servicio de sesión para esta demostración estatal\n",
        "session_service_stateful = InMemorySessionService()\n",
        "print(\"✅ New InMemorySessionService created for state demonstration.\")\n",
        "\n",
        "# Defina una nueva identificación de sesión para esta parte del tutorial\n",
        "SESSION_ID_STATEFUL = \"session_state_demo_001\"\n",
        "USER_ID_STATEFUL = \"user_state_demo\"\n",
        "\n",
        "# Definir datos de estado iniciales: el usuario prefiere Celsius inicialmente\n",
        "initial_state = {\n",
        "    \"user_preference_temperature_unit\": \"Celsius\"\n",
        "}\n",
        "\n",
        "# Crear la sesión, proporcionando el estado inicial\n",
        "session_stateful = session_service_stateful.create_session(\n",
        "    app_name=APP_NAME, # Use the consistent app name\n",
        "    user_id=USER_ID_STATEFUL,\n",
        "    session_id=SESSION_ID_STATEFUL,\n",
        "    state=initial_state # <<< Initialize state during creation\n",
        ")\n",
        "print(f\"✅ Session '{SESSION_ID_STATEFUL}' created for user '{USER_ID_STATEFUL}'.\")\n",
        "\n",
        "# Verificar que el estado inicial se estableció correctamente\n",
        "retrieved_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                         user_id=USER_ID_STATEFUL,\n",
        "                                                         session_id = SESSION_ID_STATEFUL)\n",
        "print(\"\\n--- Initial Session State ---\")\n",
        "if retrieved_session:\n",
        "    print(retrieved_session.state)\n",
        "else:\n",
        "    print(\"Error: Could not retrieve session.\")"
      ],
      "metadata": {
        "id": "wt21ea6ctFT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12018d2b-ea6e-412b-efb0-c89e56a91b2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ New InMemorySessionService created for state demonstration.\n",
            "✅ Session 'session_state_demo_001' created for user 'user_state_demo'.\n",
            "\n",
            "--- Initial Session State ---\n",
            "{'user_preference_temperature_unit': 'Celsius'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 2 \\.Crear herramienta meteorológica consciente del estado (`get_weather_stateful`) **\n",
        "\n",
        "Ahora, creamos una nueva versión de la herramienta meteorológica.Su característica clave es aceptar `Tool_Context: ToolContext` que le permite acceder a` tool_context.state`.Leerá el `user_preference_temperature_unit` y formateará la temperatura en consecuencia.\n",
        "\n",
        "\n",
        "*** Concepto clave: `ToolContext` ** Este objeto es el puente que permite que la lógica de su herramienta interactúe con el contexto de la sesión, incluida la lectura y la escritura de las variables de estado.ADK lo inyecta automáticamente si se define como el último parámetro de la función de su herramienta.\n",
        "\n",
        "\n",
        "*** Mejor práctica: ** Al leer desde el estado, use `diccionario.get ('key', default_value)` para manejar casos donde la clave aún no existirá, asegurando que su herramienta no se bloquee."
      ],
      "metadata": {
        "id": "652bNx3H16lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.tools.tool_context import ToolContext\n",
        "\n",
        "def get_weather_stateful(city: str, tool_context: ToolContext) -> dict:\n",
        "    \"\"\"Retrieves weather, converts temp unit based on session state.\"\"\"\n",
        "    print(f\"--- Tool: get_weather_stateful called for {city} ---\")\n",
        "\n",
        "# # --- Leer preferencia del estado ---\n",
        "    preferred_unit = tool_context.state.get(\"user_preference_temperature_unit\", \"Celsius\") # Default to Celsius\n",
        "    print(f\"--- Tool: Reading state 'user_preference_temperature_unit': {preferred_unit} ---\")\n",
        "\n",
        "    city_normalized = city.lower().replace(\" \", \"\")\n",
        "\n",
        "# # Datos meteorológicos simulados (siempre almacenados en Celsius internamente)\n",
        "    mock_weather_db = {\n",
        "        \"newyork\": {\"temp_c\": 25, \"condition\": \"sunny\"},\n",
        "        \"london\": {\"temp_c\": 15, \"condition\": \"cloudy\"},\n",
        "        \"tokyo\": {\"temp_c\": 18, \"condition\": \"light rain\"},\n",
        "    }\n",
        "\n",
        "    if city_normalized in mock_weather_db:\n",
        "        data = mock_weather_db[city_normalized]\n",
        "        temp_c = data[\"temp_c\"]\n",
        "        condition = data[\"condition\"]\n",
        "\n",
        "# # Temperatura de formato basada en la preferencia de estado\n",
        "        if preferred_unit == \"Fahrenheit\":\n",
        "            temp_value = (temp_c * 9/5) + 32 # Calculate Fahrenheit\n",
        "            temp_unit = \"°F\"\n",
        "        else: # Default to Celsius\n",
        "            temp_value = temp_c\n",
        "            temp_unit = \"°C\"\n",
        "\n",
        "        report = f\"The weather in {city.capitalize()} is {condition} with a temperature of {temp_value:.0f}{temp_unit}.\"\n",
        "        result = {\"status\": \"success\", \"report\": report}\n",
        "        print(f\"--- Tool: Generated report in {preferred_unit}. Result: {result} ---\")\n",
        "\n",
        "# # Ejemplo de redacción de regreso al estado (opcional para esta herramienta)\n",
        "        tool_context.state[\"last_city_checked_stateful\"] = city\n",
        "        print(f\"--- Tool: Updated state 'last_city_checked_stateful': {city} ---\")\n",
        "\n",
        "        return result\n",
        "    else:\n",
        "# # Manejar la ciudad no encontrada\n",
        "        error_msg = f\"Sorry, I don't have weather information for '{city}'.\"\n",
        "        print(f\"--- Tool: City '{city}' not found. ---\")\n",
        "        return {\"status\": \"error\", \"error_message\": error_msg}\n",
        "\n",
        "print(\"✅ State-aware 'get_weather_stateful' tool defined.\")\n"
      ],
      "metadata": {
        "id": "zK11GeWftFRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb885df-08b3-4a08-842e-2c7c92b63c3b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ State-aware 'get_weather_stateful' tool defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 3 \\.Redefinir los subgestados y actualizar el agente raíz **\n",
        "\n",
        "Para garantizar que este paso sea autónomo y se construye correctamente, primero redefinimos el `Saluding_Agent` y` Farewell_agent` exactamente como estaban en el paso 3 \\.Luego, definimos nuestro nuevo agente raíz (`weather_agent_v4_stateful`):\n",
        "\n",
        "* Utiliza la nueva herramienta `get_weather_stateful`.\n",
        "* Incluye los sub-agentes de saludo y despedida para la delegación.\n",
        "*** Crucialmente **, establece `output_key =\" last_weather_report \"` que guarda automáticamente su respuesta climática final al estado de sesión."
      ],
      "metadata": {
        "id": "UuQMolpG2Qkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 3. Redefine sub-agentes y actualice Root Agent con Output_Key\n",
        "\n",
        "# Asegurar las importaciones necesarias: agente, litellm, corredor\n",
        "from google.adk.agents import Agent\n",
        "from google.adk.models.lite_llm import LiteLlm\n",
        "from google.adk.runners import Runner\n",
        "# Asegúrese de que las herramientas 'say_hello', 'say_goodbye' se definan (del paso 3)\n",
        "# Asegurar constantes de modelo Model_gpt_4o, model_gemini_2_5_pro etc.\n",
        "\n",
        "# --- Redefine Greeting Agent (from Step 3) ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "    greeting_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"greeting_agent\",\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Agent '{greeting_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Greeting agent. Error: {e}\")\n",
        "\n",
        "# --- Redefine el agente de despedida (del paso 3) ---\n",
        "farewell_agent = None\n",
        "try:\n",
        "    farewell_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"farewell_agent\",\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Agent '{farewell_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Farewell agent. Error: {e}\")\n",
        "\n",
        "# --- Define the Updated Root Agent ---\n",
        "root_agent_stateful = None\n",
        "runner_root_stateful = None # Initialize runner\n",
        "\n",
        "# Verifique los requisitos previos antes de crear el agente raíz\n",
        "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals():\n",
        "\n",
        "    root_agent_model = MODEL_GEMINI_2_0_FLASH # Choose orchestration model\n",
        "\n",
        "    root_agent_stateful = Agent(\n",
        "        name=\"weather_agent_v4_stateful\", # New version name\n",
        "        model=root_agent_model,\n",
        "        description=\"Main agent: Provides weather (state-aware unit), delegates greetings/farewells, saves report to state.\",\n",
        "        instruction=\"You are the main Weather Agent. Your job is to provide weather using 'get_weather_stateful'. \"\n",
        "                    \"The tool will format the temperature based on user preference stored in state. \"\n",
        "                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
        "                    \"Handle only weather requests, greetings, and farewells.\",\n",
        "        tools=[get_weather_stateful], # Use the state-aware tool\n",
        "        sub_agents=[greeting_agent, farewell_agent], # Include sub-agents\n",
        "        output_key=\"last_weather_report\" # <<< Auto-save agent's final weather response\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{root_agent_stateful.name}' created using stateful tool and output_key.\")\n",
        "\n",
        "# # --- Crear corredor para este agente raíz y nuevo servicio de sesión ---\n",
        "    runner_root_stateful = Runner(\n",
        "        agent=root_agent_stateful,\n",
        "        app_name=APP_NAME,\n",
        "        session_service=session_service_stateful # Use the NEW stateful session service\n",
        "    )\n",
        "    print(f\"✅ Runner created for stateful root agent '{runner_root_stateful.agent.name}' using stateful session service.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create stateful root agent. Prerequisites missing.\")\n",
        "    if not greeting_agent: print(\" - greeting_agent definition missing.\")\n",
        "    if not farewell_agent: print(\" - farewell_agent definition missing.\")\n",
        "    if 'get_weather_stateful' not in globals(): print(\" - get_weather_stateful tool missing.\")\n"
      ],
      "metadata": {
        "id": "ox3-2hwTtFOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e93c0a-188d-4cd8-c55d-fe22497fd9e2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Agent 'greeting_agent' redefined.\n",
            "✅ Agent 'farewell_agent' redefined.\n",
            "✅ Root Agent 'weather_agent_v4_stateful' created using stateful tool and output_key.\n",
            "✅ Runner created for stateful root agent 'weather_agent_v4_stateful' using stateful session service.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 4 \\.Interactuar y probar el flujo de estado **\n",
        "\n",
        "Ahora, ejecutemos una conversación diseñada para probar las interacciones de estado utilizando el 'Runner_Root_Stateful` (asociado con nuestro agente con estado y el `session_service_stateful`).Usaremos la función `call_agent_async` definida anteriormente, asegurando que pasemos el corredor correcto, la identificación de usuario (` user_id_stateful`) e ID de sesión (`session_id_stateful`).\n",
        "\n",
        "El flujo de conversación será:\n",
        "\n",
        "1.  **Check weather (London):** The `get_weather_stateful` tool should read the initial \"Celsius\" preference from the session state initialized in Section 1. The root agent's final response (the weather report in Celsius) should get saved to `state['last_weather_report']` via the `output_key` configuration.\n",
        "2. ** Estado de actualización manual: ** modificaremos directamente*el estado almacenado dentro de la instancia `inMemorySessionService` (` session_service_stateful`).\n",
        "*** ¿Por qué la modificación directa? ** El `session_service.get_session ()` El método devuelve un*copia*de la sesión.Modificar esa copia no afectaría el estado utilizado en las ejecuciones de agentes posteriores.Para este escenario de prueba con `InMemorySessionService`, accedemos al diccionario interno` sessions` para cambiar el valor de estado * real * almacenado * para `user_preference_temperature_unit` a\" Fahrenheit \".*Nota: En aplicaciones reales, los cambios de estado generalmente se activan por herramientas o lógica de agente que devuelve `eventactions (state_delta = ...)`, no actualizaciones manuales directas.*\n",
        "3. ** Compruebe el clima nuevamente (Nueva York): ** La herramienta `get_weather_stateful` ahora debería leer la preferencia actualizada de\" fahrenheit \"del estado y convertir la temperatura en consecuencia.La respuesta * nueva * del agente raíz (clima en fahrenheit) sobrescribirá el valor anterior en `state ['last_weather_report']` debido a la 'salida_key`.\n",
        "4. ** Salude al agente: ** Verifique que la delegación al `Saluding_Agent` todavía funciona correctamente junto con las operaciones con estado.Esta interacción se convertirá en la * Última * respuesta guardada por `output_key` en esta secuencia específica.\n",
        "5. ** Inspeccione el estado final: ** Después de la conversación, recuperamos la sesión por última vez (obtener una copia) e imprimimos su estado para confirmar el `user_preference_temperature_unit` es de hecho\" fahrenheit \", observe el valor final guardado por` £key` (que será el saludo en esta ejecución) y ver el `` `Last_City_Checked Fulio` `GOOUT_KEY` (que será el saludo en esta ejecución), y ver el` `Last_City_Checked Fule` `GOOUT_KEY` (que será el saludo en esta ejecución), y ver el` `Last_City_Checked Fule '` `GOOUT_KEY` (que será el saludo en esta ejecución) y ver el` `` `` `` `` `` `` `` `Last_City_Checked Fulio' '."
      ],
      "metadata": {
        "id": "P394DfSb2aOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 4. Interactuar para probar el flujo de estado y la salida_key\n",
        "\n",
        "# Asegúrese de que el corredor estatal (runner_root_stateful) esté disponible en la celda anterior\n",
        "# Asegúrese de que Call_agent_async, user_id_stateful, session_id_stateful, app_name se definan\n",
        "\n",
        "if 'runner_root_stateful' in globals() and runner_root_stateful:\n",
        "  async def run_stateful_conversation():\n",
        "      print(\"\\n--- Testing State: Temp Unit Conversion & output_key ---\")\n",
        "\n",
        "# # 1. Verifique el clima (usa el estado inicial: Celsius)\n",
        "      print(\"--- Turn 1: Requesting weather in London (expect Celsius) ---\")\n",
        "      await call_agent_async(query= \"What's the weather in London?\",\n",
        "                             runner=runner_root_stateful,\n",
        "                             user_id=USER_ID_STATEFUL,\n",
        "                             session_id=SESSION_ID_STATEFUL\n",
        "                            )\n",
        "\n",
        "# # 2. Actualice manualmente la preferencia de estado a Fahrenheit: modifique directamente el almacenamiento\n",
        "      print(\"\\n--- Manually Updating State: Setting unit to Fahrenheit ---\")\n",
        "      try:\n",
        "# # Acceda al almacenamiento interno directamente: esto es específico de InMemorySessionService para pruebas\n",
        "          stored_session = session_service_stateful.sessions[APP_NAME][USER_ID_STATEFUL][SESSION_ID_STATEFUL]\n",
        "          stored_session.state[\"user_preference_temperature_unit\"] = \"Fahrenheit\"\n",
        "# # Opcional: es posible que desee actualizar la marca de tiempo también si alguna lógica depende de ella\n",
        "# # Tiempo de importación\n",
        "# # stored_session.last_update_time = time.time ()\n",
        "          print(f\"--- Stored session state updated. Current 'user_preference_temperature_unit': {stored_session.state['user_preference_temperature_unit']} ---\")\n",
        "      except KeyError:\n",
        "          print(f\"--- Error: Could not retrieve session '{SESSION_ID_STATEFUL}' from internal storage for user '{USER_ID_STATEFUL}' in app '{APP_NAME}' to update state. Check IDs and if session was created. ---\")\n",
        "      except Exception as e:\n",
        "           print(f\"--- Error updating internal session state: {e} ---\")\n",
        "\n",
        "# # 3. Verifique el clima nuevamente (la herramienta ahora debe usar Fahrenheit)\n",
        "# # Esto también actualizará 'last_weather_report' a través de output_key\n",
        "      print(\"\\n--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\")\n",
        "      await call_agent_async(query= \"Tell me the weather in New York.\",\n",
        "                             runner=runner_root_stateful,\n",
        "                             user_id=USER_ID_STATEFUL,\n",
        "                             session_id=SESSION_ID_STATEFUL\n",
        "                            )\n",
        "\n",
        "# # 4. Pruebe la delegación básica (aún debería funcionar)\n",
        "# # Esto actualizará 'last_weather_report' nuevamente, sobrescribiendo el informe meteorológico de Nueva York\n",
        "      print(\"\\n--- Turn 3: Sending a greeting ---\")\n",
        "      await call_agent_async(query= \"Hi!\",\n",
        "                             runner=runner_root_stateful,\n",
        "                             user_id=USER_ID_STATEFUL,\n",
        "                             session_id=SESSION_ID_STATEFUL\n",
        "                            )\n",
        "\n",
        "# # Ejecutar la conversación\n",
        "  await run_stateful_conversation()\n",
        "\n",
        "# # Inspeccione el estado de la sesión final después de la conversación\n",
        "  print(\"\\n--- Inspecting Final Session State ---\")\n",
        "  final_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                       user_id= USER_ID_STATEFUL,\n",
        "                                                       session_id=SESSION_ID_STATEFUL)\n",
        "  if final_session:\n",
        "      print(f\"Final Preference: {final_session.state.get('user_preference_temperature_unit')}\")\n",
        "      print(f\"Final Last Weather Report (from output_key): {final_session.state.get('last_weather_report')}\")\n",
        "      print(f\"Final Last City Checked (by tool): {final_session.state.get('last_city_checked_stateful')}\")\n",
        "# # Imprimir estado completo para una vista detallada\n",
        "# # print (f \"estado completo: {final_session.state}\")\n",
        "  else:\n",
        "      print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
        "\n",
        "else:\n",
        "  print(\"\\n⚠️ Skipping state test conversation. Stateful root agent runner ('runner_root_stateful') is not available.\")"
      ],
      "metadata": {
        "id": "WYZfRCp0tFLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828c9770-8e4f-48b1-c3f0-898241f66f1a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing State: Temp Unit Conversion & output_key ---\n",
            "--- Turn 1: Requesting weather in London (expect Celsius) ---\n",
            "\n",
            ">>> User Query: What's the weather in London?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather_stateful called for London ---\n",
            "--- Tool: Reading state 'user_preference_temperature_unit': Celsius ---\n",
            "--- Tool: Generated report in Celsius. Result: {'status': 'success', 'report': 'The weather in London is cloudy with a temperature of 15°C.'} ---\n",
            "--- Tool: Updated state 'last_city_checked_stateful': London ---\n",
            "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
            "\n",
            "\n",
            "--- Manually Updating State: Setting unit to Fahrenheit ---\n",
            "--- Stored session state updated. Current 'user_preference_temperature_unit': Fahrenheit ---\n",
            "\n",
            "--- Turn 2: Requesting weather in New York (expect Fahrenheit) ---\n",
            "\n",
            ">>> User Query: Tell me the weather in New York.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather_stateful called for New York ---\n",
            "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
            "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in New york is sunny with a temperature of 77°F.'} ---\n",
            "--- Tool: Updated state 'last_city_checked_stateful': New York ---\n",
            "<<< Agent Response: The weather in New york is sunny with a temperature of 77°F.\n",
            "\n",
            "\n",
            "--- Turn 3: Sending a greeting ---\n",
            "\n",
            ">>> User Query: Hi!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n",
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n",
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: say_hello called with name: there ---\n",
            "<<< Agent Response: Hello, there!\n",
            "\n",
            "\n",
            "--- Inspecting Final Session State ---\n",
            "Final Preference: Fahrenheit\n",
            "Final Last Weather Report (from output_key): Hello, there!\n",
            "\n",
            "Final Last City Checked (by tool): New York\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Al revisar el flujo de conversación y la impresión de estado de sesión final, puede confirmar:\n",
        "\n",
        "*** Estado Leer: ** La herramienta meteorológica (`get_weather_stateful`) lea correctamente` user_preference_temperature_unit` del estado, inicialmente usando \"Celsius\" para Londres.\n",
        "*** Actualización de estado: ** La modificación directa cambió con éxito la preferencia almacenada a \"Fahrenheit\".\n",
        "*** Estado de lectura (actualizado): ** La herramienta posteriormente leyó \"Fahrenheit\" cuando se le pidió el clima de Nueva York y realizó la conversión.\n",
        "*** Escritura de estado de la herramienta: ** La herramienta escribió con éxito el `last_city_checked_stateful` (\" Nueva York \"después de la segunda verificación del clima) en el estado a través de` tool_context.state`.\n",
        "*** Delegación: ** La delegación al `Saluding_Agent` para\" ¡Hola! \"funcionó correctamente incluso después de las modificaciones de estado.\n",
        "*** `Output_Key`: ** El` output_key = \"last_weather_rePort\" `guardó con éxito la respuesta*final*final*del agente raíz para*cada turno*donde el agente raíz fue el que finalmente respondió.En esta secuencia, la última respuesta fue el saludo (\"¡Hola, allí!\"), De modo que sobrescribió el informe meteorológico en la clave del estado.\n",
        "*** Estado final: ** La verificación final confirma la preferencia persistida como \"Fahrenheit\".\n",
        "\n",
        "Ahora ha integrado con éxito el estado de sesión para personalizar el comportamiento de los agentes utilizando el estado `toolcontext`, manipulado manualmente para probar 'inMemorySessionService`, y observó cómo' Output_Key` proporciona un mecanismo simple para guardar la última respuesta del agente al estado.Esta comprensión fundamental de la gestión del estado es clave, ya que procedemos a implementar barandillas de seguridad utilizando devoluciones de llamada en los próximos pasos.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "mqiG4SAX2l8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 5: Agregar seguridad \\- Entrada GuardRail con `antes_model_callback`\n",
        "\n",
        "Nuestro equipo de agentes se está volviendo más capaz, recordando las preferencias y el uso de herramientas de manera efectiva.Sin embargo, en los escenarios del mundo real, a menudo necesitamos mecanismos de seguridad para controlar el comportamiento del agente * antes de * las solicitudes potencialmente problemáticas incluso alcanzan el modelo de lenguaje grande (LLM).\n",
        "\n",
        "ADK proporciona ** devoluciones de llamada **: funciones que le permiten conectarse a puntos específicos en el ciclo de vida de ejecución del agente.El `antes_model_callback` es particularmente útil para la seguridad de la entrada.\n",
        "\n",
        "** ¿Qué es `antes_model_callback`? **\n",
        "\n",
        "* Es una función de Python que define que ADK ejecuta * justo antes de * un agente envía su solicitud compilada (incluido el historial de conversación, las instrucciones y el último mensaje de usuario) al LLM subyacente.\n",
        "*** Propósito: ** Inspeccionar la solicitud, modificarla si es necesario o bloquearla por completo en base a reglas predefinidas.\n",
        "\n",
        "** Casos de uso comunes: **\n",
        "\n",
        "*** Validación/filtrado de entrada: ** Compruebe si la entrada del usuario cumple con los criterios o contiene contenido no permitido (como PII o palabras clave).\n",
        "*** Las barandillas: ** Evite que las solicitudes dañinas, fuera de tema o que violen las políticas sean procesadas por el LLM.\n",
        "*** Modificación de indicación dinámica: ** Agregue información oportuna (por ejemplo, desde el estado de la sesión) al contexto de solicitud de LLM justo antes de enviar.\n",
        "\n",
        "** Cómo funciona: **\n",
        "\n",
        "1. Defina una función que acepte `callback_context: llameBackContext` y` llm_request: llmRequest`.\n",
        "* `Callback_context`: proporciona acceso a la información del agente, estado de sesión (` callback_context.state`), etc.\n",
        "* `llm_request`: contiene la carga útil completa destinada al LLM (` contenido`, `config`).\n",
        "2. Dentro de la función:\n",
        "*** Inspeccionar: ** Examine `llm_request.contents` (especialmente el último mensaje de usuario).\n",
        "*** modificar (usar precaución): ** usted*puede*cambiar partes de `llm_request`.\n",
        "*** Bloque (GuardRail): ** Devuelve un objeto `llmResponse`.ADK devolverá esta respuesta de inmediato, * omitiendo * la llamada LLM para ese turno.\n",
        "*** Permitir: ** Return `None`.ADK procede a llamar al LLM con la solicitud (potencialmente modificada).\n",
        "\n",
        "** En este paso, lo haremos: **\n",
        "\n",
        "1. Defina una función `antes_model_callback` (` block_keyword_guardrail`) que verifica la entrada del usuario para una palabra clave específica (\"bloque\").\n",
        "2. Actualice nuestro agente raíz con estado (`Weather_agent_V4_Stateful` del paso 4 \\) para usar esta devolución de llamada.\n",
        "3. Cree un nuevo corredor asociado con este agente actualizado pero utilizando el * mismo servicio de sesión con estado * para mantener la continuidad del estado.\n",
        "4. Pruebe la barandilla enviando solicitudes normales y que contienen palabras clave."
      ],
      "metadata": {
        "id": "JwTcmu0oaEiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 1 \\.Definir la función de devolución de llamada de la barandilla **\n",
        "\n",
        "Esta función inspeccionará el último mensaje de usuario dentro del contenido 'LLM_REQUEST`.Si encuentra \"bloqueo\" (insensible al caso), construye y devuelve un `llmResponse` para bloquear el flujo;De lo contrario, devuelve `Ninguno`."
      ],
      "metadata": {
        "id": "G7m6zhMv4Zss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 1. Defina la barandilla de guía anterior_model_callback\n",
        "\n",
        "# Asegúrese de que las importaciones necesarias estén disponibles\n",
        "from google.adk.agents.callback_context import CallbackContext\n",
        "from google.adk.models.llm_request import LlmRequest\n",
        "from google.adk.models.llm_response import LlmResponse\n",
        "from google.genai import types # For creating response content\n",
        "from typing import Optional\n",
        "\n",
        "def block_keyword_guardrail(\n",
        "    callback_context: CallbackContext, llm_request: LlmRequest\n",
        ") -> Optional[LlmResponse]:\n",
        "    \"\"\"\n",
        "    Inspects the latest user message for 'BLOCK'. If found, blocks the LLM call\n",
        "    and returns a predefined LlmResponse. Otherwise, returns None to proceed.\n",
        "    \"\"\"\n",
        "    agent_name = callback_context.agent_name # Get the name of the agent whose model call is being intercepted\n",
        "    print(f\"--- Callback: block_keyword_guardrail running for agent: {agent_name} ---\")\n",
        "\n",
        "# # Extraer el texto del último mensaje de usuario en el historial de solicitudes\n",
        "    last_user_message_text = \"\"\n",
        "    if llm_request.contents:\n",
        "# # Encuentra el mensaje más reciente con el rol 'Usuario'\n",
        "        for content in reversed(llm_request.contents):\n",
        "            if content.role == 'user' and content.parts:\n",
        "# # Suponiendo que el texto esté en la primera parte para simplificar\n",
        "                if content.parts[0].text:\n",
        "                    last_user_message_text = content.parts[0].text\n",
        "                    break # Found the last user message text\n",
        "\n",
        "    print(f\"--- Callback: Inspecting last user message: '{last_user_message_text[:100]}...' ---\") # Log first 100 chars\n",
        "\n",
        "# # --- Lógica de barandilla ---\n",
        "    keyword_to_block = \"BLOCK\"\n",
        "    if keyword_to_block in last_user_message_text.upper(): # Case-insensitive check\n",
        "        print(f\"--- Callback: Found '{keyword_to_block}'. Blocking LLM call! ---\")\n",
        "# # Opcionalmente, establezca una bandera en el estado para grabar el evento de bloque\n",
        "        callback_context.state[\"guardrail_block_keyword_triggered\"] = True\n",
        "        print(f\"--- Callback: Set state 'guardrail_block_keyword_triggered': True ---\")\n",
        "\n",
        "# # Construya y devuelve una respuesta LLM para detener el flujo y enviar esto en su lugar\n",
        "        return LlmResponse(\n",
        "            content=types.Content(\n",
        "                role=\"model\", # Mimic a response from the agent's perspective\n",
        "                parts=[types.Part(text=f\"I cannot process this request because it contains the blocked keyword '{keyword_to_block}'.\")],\n",
        "            )\n",
        "# # Nota: también puede establecer un campo ERROR_MESSAGE aquí si sea necesario\n",
        "        )\n",
        "    else:\n",
        "# # Palabra clave no encontrada, permita que la solicitud proceda al LLM\n",
        "        print(f\"--- Callback: Keyword not found. Allowing LLM call for {agent_name}. ---\")\n",
        "        return None # Returning None signals ADK to continue normally\n",
        "\n",
        "print(\"✅ block_keyword_guardrail function defined.\")\n"
      ],
      "metadata": {
        "id": "JZay2mbHaHSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ba610dc-9419-4698-c03c-5d288739eca1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ block_keyword_guardrail function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 2 \\.Actualice Root Agent para usar la devolución de llamada **\n",
        "\n",
        "Redefinimos el agente raíz, agregando el parámetro `antes_model_callback` y apuntándolo a nuestra nueva función de barandilla.Le daremos un nuevo nombre de versión para mayor claridad.\n",
        "\n",
        "* IMPORTANTE:* Necesitamos redefinir los sub-agentes (`Saluding_Agent`,` Farewell_agent`) y la herramienta de estado (`get_weather_stateful`) dentro de este contexto si aún no están disponibles en los pasos anteriores, asegurando que la definición del agente raíz tenga acceso a todos sus componentes."
      ],
      "metadata": {
        "id": "giawLd9VaI7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 2. Actualice Root Agent con antes_Model_Callback\n",
        "\n",
        "\n",
        "# --- Redefine los sub-agentes (asegura que existan en este contexto) ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "# # Use una constante de modelo definido\n",
        "    greeting_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"greeting_agent\", # Keep original name for consistency\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Sub-Agent '{greeting_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Greeting agent. Check Model/API Key ({MODEL_GPT_4O}). Error: {e}\")\n",
        "\n",
        "farewell_agent = None\n",
        "try:\n",
        "# # Use una constante de modelo definido\n",
        "    farewell_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"farewell_agent\", # Keep original name\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Sub-Agent '{farewell_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Farewell agent. Check Model/API Key ({MODEL_GPT_4O}). Error: {e}\")\n",
        "\n",
        "\n",
        "# --- Defina al agente raíz con la devolución de llamada ---\n",
        "root_agent_model_guardrail = None\n",
        "runner_root_model_guardrail = None\n",
        "\n",
        "# Verifique todos los componentes antes de continuar\n",
        "if greeting_agent and farewell_agent and 'get_weather_stateful' in globals() and 'block_keyword_guardrail' in globals():\n",
        "\n",
        "# # Use un modelo definido constante como model_gemini_2_5_pro\n",
        "    root_agent_model = MODEL_GEMINI_2_0_FLASH\n",
        "\n",
        "    root_agent_model_guardrail = Agent(\n",
        "        name=\"weather_agent_v5_model_guardrail\", # New version name for clarity\n",
        "        model=root_agent_model,\n",
        "        description=\"Main agent: Handles weather, delegates greetings/farewells, includes input keyword guardrail.\",\n",
        "        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n",
        "                    \"Delegate simple greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
        "                    \"Handle only weather requests, greetings, and farewells.\",\n",
        "        tools=[get_weather],\n",
        "        sub_agents=[greeting_agent, farewell_agent], # Reference the redefined sub-agents\n",
        "        output_key=\"last_weather_report\", # Keep output_key from Step 4\n",
        "        before_model_callback=block_keyword_guardrail # <<< Assign the guardrail callback\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{root_agent_model_guardrail.name}' created with before_model_callback.\")\n",
        "\n",
        "# # --- Crear corredor para este agente, utilizando el mismo servicio de sesión con estado ---\n",
        "# # Asegurar session_service_stateful existe desde el paso 4\n",
        "    if 'session_service_stateful' in globals():\n",
        "        runner_root_model_guardrail = Runner(\n",
        "            agent=root_agent_model_guardrail,\n",
        "            app_name=APP_NAME, # Use consistent APP_NAME\n",
        "            session_service=session_service_stateful # <<< Use the service from Step 4\n",
        "        )\n",
        "        print(f\"✅ Runner created for guardrail agent '{runner_root_model_guardrail.agent.name}', using stateful session service.\")\n",
        "    else:\n",
        "        print(\"❌ Cannot create runner. 'session_service_stateful' from Step 4 is missing.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create root agent with model guardrail. One or more prerequisites are missing or failed initialization:\")\n",
        "    if not greeting_agent: print(\"   - Greeting Agent\")\n",
        "    if not farewell_agent: print(\"   - Farewell Agent\")\n",
        "    if 'get_weather_stateful' not in globals(): print(\"   - 'get_weather_stateful' tool\")\n",
        "    if 'block_keyword_guardrail' not in globals(): print(\"   - 'block_keyword_guardrail' callback\")"
      ],
      "metadata": {
        "id": "IRoMmJ9V_cuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba3ca63b-40dc-4a2e-8f4b-75c1c44c2a20"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sub-Agent 'greeting_agent' redefined.\n",
            "✅ Sub-Agent 'farewell_agent' redefined.\n",
            "✅ Root Agent 'weather_agent_v5_model_guardrail' created with before_model_callback.\n",
            "✅ Runner created for guardrail agent 'weather_agent_v5_model_guardrail', using stateful session service.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 3 \\.Interactuar para probar la barandilla **\n",
        "\n",
        "Probemos el comportamiento de la barandilla.Usaremos la * misma sesión * (`session_id_stateful`) como en el paso 4 para mostrar que el estado persiste en estos cambios.\n",
        "\n",
        "1. Envíe una solicitud de clima normal (debe pasar la barandilla y ejecutar).\n",
        "2. Envíe una solicitud que contenga \"bloque\" (debe ser interceptado por la devolución de llamada).\n",
        "3. Envíe un saludo (debe pasar la barandilla del agente raíz, ser delegado y ejecutar normalmente)."
      ],
      "metadata": {
        "id": "R2EW2LSS4wnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 3. Interactúa para probar la barandilla de entrada del modelo\n",
        "\n",
        "# Asegúrese de que el corredor para el agente de barandilla esté disponible\n",
        "if runner_root_model_guardrail:\n",
        "  async def run_guardrail_test_conversation():\n",
        "      print(\"\\n--- Testing Model Input Guardrail ---\")\n",
        "\n",
        "# # Use el corredor para el agente con la devolución de llamada y la ID de sesión de estado existente\n",
        "  interaction_func = lambda query: call_agent_async(query,\n",
        "    runner_root_model_guardrail, USER_ID_STATEFUL, SESSION_ID_STATEFUL # <-- Pass correct IDs\n",
        "  )\n",
        "# # 1. Solicitud normal (la devolución de llamada lo permite, debe usar Fahrenheit desde el paso 4 Cambio de estado)\n",
        "  await interaction_func(\"What is the weather in London?\")\n",
        "\n",
        "# # 2. Solicitud que contiene la palabra clave bloqueada\n",
        "  await interaction_func(\"BLOCK the request for weather in Tokyo\")\n",
        "\n",
        "# # 3. Saludo normal (la devolución de llamada permite que el agente raíz, la delegación ocurra)\n",
        "  await interaction_func(\"Hello again\")\n",
        "\n",
        "\n",
        "# # Ejecutar la conversación\n",
        "  await run_guardrail_test_conversation()\n",
        "\n",
        "# # Opcional: Verifique el estado de la bandera de activación establecida por la devolución de llamada\n",
        "  final_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                       user_id=USER_ID_STATEFUL,\n",
        "                                                       session_id=SESSION_ID_STATEFUL)\n",
        "  if final_session:\n",
        "      print(\"\\n--- Final Session State (After Guardrail Test) ---\")\n",
        "      print(f\"Guardrail Triggered Flag: {final_session.state.get('guardrail_block_keyword_triggered')}\")\n",
        "      print(f\"Last Weather Report: {final_session.state.get('last_weather_report')}\") # Should be London weather\n",
        "      print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit')}\") # Should be Fahrenheit\n",
        "  else:\n",
        "      print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
        "\n",
        "else:\n",
        "  print(\"\\n⚠️ Skipping model guardrail test. Runner ('runner_root_model_guardrail') is not available.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4EnMiXX8aO9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c70035-4a2a-4568-eb91-548408ac6ac3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> User Query: What is the weather in London?\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'What is the weather in London?...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v5_model_guardrail. ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: get_weather called for city: London ---\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'What is the weather in London?...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v5_model_guardrail. ---\n",
            "<<< Agent Response: It's cloudy in London with a temperature of 15°C.\n",
            "\n",
            "\n",
            ">>> User Query: BLOCK the request for weather in Tokyo\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'BLOCK the request for weather in Tokyo...' ---\n",
            "--- Callback: Found 'BLOCK'. Blocking LLM call! ---\n",
            "--- Callback: Set state 'guardrail_block_keyword_triggered': True ---\n",
            "<<< Agent Response: I cannot process this request because it contains the blocked keyword 'BLOCK'.\n",
            "\n",
            ">>> User Query: Hello again\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v5_model_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'Hello again...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v5_model_guardrail. ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n",
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n",
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n",
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tool: say_hello called with name: there ---\n",
            "<<< Agent Response: Hello, there!\n",
            "\n",
            "\n",
            "--- Testing Model Input Guardrail ---\n",
            "\n",
            "--- Final Session State (After Guardrail Test) ---\n",
            "Guardrail Triggered Flag: True\n",
            "Last Weather Report: Hello, there!\n",
            "\n",
            "Temperature Unit: Fahrenheit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Observe el flujo de ejecución:\n",
        "\n",
        "1. ** London Weather: ** La devolución de llamada se ejecuta para `Weather_Agent_V5_Model_Guardrail`, inspecciona el mensaje, imprime la palabra clave\" no se encuentra. Permitiendo la llamada LLM \", y devuelve` Ninguno`.El agente procede, llama a la herramienta `get_weather_stateful` (que utiliza la preferencia\" Fahrenheit \"del cambio de estado del paso 4) y devuelve el clima.Esta respuesta actualiza `last_weather_report` a través de` output_key`.\n",
        "2. ** Solicitud de bloque: ** La devolución de llamada se ejecuta nuevamente para `weather_agent_v5_model_guardrail`, inspecciona el mensaje, encuentra\" bloque \", imprime\" Bloqueo de LLM Call \\! \", Establece la bandera de estado y devuelve el` llMresponse` predefinido.El LLM subyacente del agente es * nunca se llama * para este turno.El usuario ve el mensaje de bloqueo de la devolución de llamada.\n",
        "3. ** Hola de nuevo: ** La devolución de llamada se ejecuta para `Weather_agent_V5_Model_Guardrail`, permite la solicitud.El agente raíz luego delega a `saludo_agent`.* Nota: El `antes_model_callback` definido en el agente raíz no se aplica automáticamente a los subciburentes.* El` Saluding_Agent` continúa normalmente, llama a su herramienta `say_hello` y devuelve el saludo.\n",
        "\n",
        "¡Ha implementado con éxito una capa de seguridad de entrada \\!El `antes_model_callback` proporciona un mecanismo poderoso para hacer cumplir las reglas y controlar el comportamiento del agente * antes de * se realizan llamadas LLM costosas o potencialmente riesgosas.A continuación, aplicaremos un concepto similar para agregar barandillas alrededor del uso de herramientas."
      ],
      "metadata": {
        "id": "e5D0KaW-aQ8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 6: Agregar seguridad \\- Argumento de herramienta GuardRail (`antes_tool_callback`)\n",
        "\n",
        "En el paso 5, agregamos una barandilla para inspeccionar y potencialmente bloquear la entrada del usuario * antes de * llegar al LLM.Ahora, agregaremos otra capa de control * después de * El LLM ha decidido usar una herramienta pero * antes * esa herramienta realmente se ejecuta.Esto es útil para validar los * argumentos * El LLM quiere pasar a la herramienta.\n",
        "\n",
        "ADK proporciona el `antes_tool_callback` para este propósito preciso.\n",
        "\n",
        "** ¿Qué es `antes_tool_callback`? **\n",
        "\n",
        "* Es una función de Python ejecutada solo * antes de * Se ejecuta una función de herramienta específica, después de que el LLM ha solicitado su uso y decidió los argumentos.\n",
        "*** Propósito: ** Validar los argumentos de la herramienta, evitar la ejecución de la herramienta basada en entradas específicas, modificar los argumentos dinámicamente o hacer cumplir las políticas de uso de recursos.\n",
        "\n",
        "** Casos de uso comunes: **\n",
        "\n",
        "*** Validación de argumentos: ** Compruebe si los argumentos proporcionados por el LLM son válidos, dentro de los rangos permitidos o se ajustan a los formatos esperados.\n",
        "*** Protección de recursos: ** Evite que las herramientas se llamen con entradas que pueden ser costosas, acceder a datos restringidos o causar efectos secundarios no deseados (por ejemplo, bloquear las llamadas de API para ciertos parámetros).\n",
        "*** Modificación de argumentos dinámicos: ** Ajuste los argumentos basados ​​en el estado de la sesión u otra información contextual antes de que la herramienta se ejecute.\n",
        "\n",
        "** Cómo funciona: **\n",
        "\n",
        "1. Defina una función que acepte `herramienta: basetool`,` args: dict [str, any] `y` tool_context: toolcontext`.\n",
        "* `Tool`: el objeto de herramienta a punto de llamarse (Inspeccionar` Tool.name`).\n",
        "* `Args`: El Diccionario de Argumentos que el LLM generó para la herramienta.\n",
        "* `Tool_context`: proporciona acceso al estado de sesión (` tool_context.state`), información del agente, etc.\n",
        "2. Dentro de la función:\n",
        "*** Inspeccionar: ** Examine el diccionario `Tool.name` y` Args`.\n",
        "*** Modificar: ** Cambiar valores dentro del diccionario `Args`*directamente*.Si devuelve `None`, la herramienta se ejecuta con estos args modificados.\n",
        "*** Bloque/anulación (Guarrail): ** Devuelve un Diccionario ** **.ADK trata este diccionario como el * resultado * de la llamada de la herramienta, completamente * omitiendo * la ejecución de la función de herramienta original.El diccionario debería igualar el formato de retorno esperado de la herramienta que está bloqueando.\n",
        "*** Permitir: ** Return `None`.ADK procede a ejecutar la función de herramienta real con los argumentos (potencialmente modificados).\n",
        "\n",
        "** En este paso, lo haremos: **\n",
        "\n",
        "1. Defina una función `antes_tool_callback` (` block_paris_tool_guardrail`) que verifica específicamente si la herramienta `get_weather_stateful` se llama con la ciudad\" París \".\n",
        "2. Si se detecta \"París\", la devolución de llamada bloqueará la herramienta y devolverá un diccionario de error personalizado.\n",
        "3. Actualice nuestro agente root (`weather_agent_v6_tool_guardrail`) para incluir * ambos * el` antes_model_callback` y este nuevo `antes_tool_callback`.\n",
        "4. Cree un nuevo corredor para este agente, utilizando el mismo servicio de sesión con estado.\n",
        "5. Pruebe el flujo solicitando el clima para las ciudades permitidas y la ciudad bloqueada (\"París\")."
      ],
      "metadata": {
        "id": "ZnH5C0IRaqet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 1 \\.Defina la función de devolución de llamada de la barandilla de la herramienta **\n",
        "\n",
        "Esta función se dirige a la herramienta `get_weather_stateful`.Verifica el argumento 'Ciudad'.Si es \"París\", devuelve un diccionario de error que se parece a la propia respuesta de error de la herramienta.De lo contrario, permite que la herramienta se ejecute devolviendo `none`."
      ],
      "metadata": {
        "id": "H5myniS17Q5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 1. Defina la barandilla de Guardia antes_Tool_Callback\n",
        "\n",
        "# Asegúrese de que las importaciones necesarias estén disponibles\n",
        "from google.adk.tools.base_tool import BaseTool\n",
        "from google.adk.tools.tool_context import ToolContext\n",
        "from typing import Optional, Dict, Any # For type hints\n",
        "\n",
        "def block_paris_tool_guardrail(\n",
        "    tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext\n",
        ") -> Optional[Dict]:\n",
        "    \"\"\"\n",
        "    Checks if 'get_weather_stateful' is called for 'Paris'.\n",
        "    If so, blocks the tool execution and returns a specific error dictionary.\n",
        "    Otherwise, allows the tool call to proceed by returning None.\n",
        "    \"\"\"\n",
        "    tool_name = tool.name\n",
        "    agent_name = tool_context.agent_name # Agent attempting the tool call\n",
        "    print(f\"--- Callback: block_paris_tool_guardrail running for tool '{tool_name}' in agent '{agent_name}' ---\")\n",
        "    print(f\"--- Callback: Inspecting args: {args} ---\")\n",
        "\n",
        "# # --- Lógica de barandilla ---\n",
        "    target_tool_name = \"get_weather_stateful\" # Match the function name used by FunctionTool\n",
        "    blocked_city = \"paris\"\n",
        "\n",
        "# # Compruebe si es la herramienta correcta y el argumento de la ciudad coincide con la ciudad bloqueada\n",
        "    if tool_name == target_tool_name:\n",
        "        city_argument = args.get(\"city\", \"\") # Safely get the 'city' argument\n",
        "        if city_argument and city_argument.lower() == blocked_city:\n",
        "            print(f\"--- Callback: Detected blocked city '{city_argument}'. Blocking tool execution! ---\")\n",
        "# # Opcionalmente actualizar el estado\n",
        "            tool_context.state[\"guardrail_tool_block_triggered\"] = True\n",
        "            print(f\"--- Callback: Set state 'guardrail_tool_block_triggered': True ---\")\n",
        "\n",
        "# # Devolver un diccionario que coincida con el formato de salida esperado de la herramienta para errores\n",
        "# # Este diccionario se convierte en el resultado de la herramienta, omitiendo la ejecución de la herramienta real.\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"error_message\": f\"Policy restriction: Weather checks for '{city_argument.capitalize()}' are currently disabled by a tool guardrail.\"\n",
        "            }\n",
        "        else:\n",
        "             print(f\"--- Callback: City '{city_argument}' is allowed for tool '{tool_name}'. ---\")\n",
        "    else:\n",
        "        print(f\"--- Callback: Tool '{tool_name}' is not the target tool. Allowing. ---\")\n",
        "\n",
        "\n",
        "# # Si las verificaciones anteriores no devuelven un diccionario, permita que la herramienta ejecute\n",
        "    print(f\"--- Callback: Allowing tool '{tool_name}' to proceed. ---\")\n",
        "    return None # Returning None allows the actual tool function to run\n",
        "\n",
        "print(\"✅ block_paris_tool_guardrail function defined.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g4wOLl6aastz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe61fb6-b4a1-4a0f-c9ae-f18f6defdb7e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ block_paris_tool_guardrail function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 2 \\.Actualizar el agente root para usar ambas devoluciones de llamada **\n",
        "\n",
        "Redefinimos el agente raíz nuevamente (`weather_agent_v6_tool_guardrail`), esta vez agregando el parámetro` antes_tool_callback` junto con el `antes_model_callback` del paso 5 \\.\n",
        "\n",
        "* Ejecución autónoma Nota:* Similar al Paso 5, asegurar que todos los requisitos previos (subcásgenes, herramientas, `antes_model_callback`) se definan o estén disponibles en el contexto de ejecución antes de definir este agente."
      ],
      "metadata": {
        "id": "4d01OYJlauSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 2. Actualice Root Agent con ambas devoluciones de llamada (autónomo)\n",
        "\n",
        "# --- Asegúrese de que se definan los requisitos previos ---\n",
        "# (Incluya o garantice la ejecución de definiciones para: agente, litellm, corredor, herramientas,\n",
        "# Modelo constantes, say_hello, say_goodbye, saludo_agent, adiós_agent,\n",
        "# get_weather_stateful, block_keyword_guardrail, block_paris_tool_guardrail)\n",
        "\n",
        "# --- Redefine los sub-agentes (asegura que existan en este contexto) ---\n",
        "greeting_agent = None\n",
        "try:\n",
        "# # Utilice un modelo definido constante como model_gpt_4o\n",
        "    greeting_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"greeting_agent\", # Keep original name for consistency\n",
        "        instruction=\"You are the Greeting Agent. Your ONLY task is to provide a friendly greeting using the 'say_hello' tool. Do nothing else.\",\n",
        "        description=\"Handles simple greetings and hellos using the 'say_hello' tool.\",\n",
        "        tools=[say_hello],\n",
        "    )\n",
        "    print(f\"✅ Sub-Agent '{greeting_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Greeting agent. Check Model/API Key ({MODEL_GPT_4O}). Error: {e}\")\n",
        "\n",
        "farewell_agent = None\n",
        "try:\n",
        "# # Utilice un modelo definido constante como model_gpt_4o\n",
        "    farewell_agent = Agent(\n",
        "        model=MODEL_GEMINI_2_0_FLASH,\n",
        "        name=\"farewell_agent\", # Keep original name\n",
        "        instruction=\"You are the Farewell Agent. Your ONLY task is to provide a polite goodbye message using the 'say_goodbye' tool. Do not perform any other actions.\",\n",
        "        description=\"Handles simple farewells and goodbyes using the 'say_goodbye' tool.\",\n",
        "        tools=[say_goodbye],\n",
        "    )\n",
        "    print(f\"✅ Sub-Agent '{farewell_agent.name}' redefined.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Could not redefine Farewell agent. Check Model/API Key ({MODEL_GPT_4O}). Error: {e}\")\n",
        "\n",
        "# --- Defina al agente raíz con ambas devoluciones de llamada ---\n",
        "root_agent_tool_guardrail = None\n",
        "runner_root_tool_guardrail = None\n",
        "\n",
        "if ('greeting_agent' in globals() and greeting_agent and\n",
        "    'farewell_agent' in globals() and farewell_agent and\n",
        "    'get_weather_stateful' in globals() and\n",
        "    'block_keyword_guardrail' in globals() and\n",
        "    'block_paris_tool_guardrail' in globals()):\n",
        "\n",
        "    root_agent_model = MODEL_GEMINI_2_0_FLASH\n",
        "\n",
        "    root_agent_tool_guardrail = Agent(\n",
        "        name=\"weather_agent_v6_tool_guardrail\", # New version name\n",
        "        model=root_agent_model,\n",
        "        description=\"Main agent: Handles weather, delegates, includes input AND tool guardrails.\",\n",
        "        instruction=\"You are the main Weather Agent. Provide weather using 'get_weather_stateful'. \"\n",
        "                    \"Delegate greetings to 'greeting_agent' and farewells to 'farewell_agent'. \"\n",
        "                    \"Handle only weather, greetings, and farewells.\",\n",
        "        tools=[get_weather_stateful],\n",
        "        sub_agents=[greeting_agent, farewell_agent],\n",
        "        output_key=\"last_weather_report\",\n",
        "        before_model_callback=block_keyword_guardrail, # Keep model guardrail\n",
        "        before_tool_callback=block_paris_tool_guardrail # <<< Add tool guardrail\n",
        "    )\n",
        "    print(f\"✅ Root Agent '{root_agent_tool_guardrail.name}' created with BOTH callbacks.\")\n",
        "\n",
        "# # --- Crear corredor, usando el mismo servicio de sesión con estado ---\n",
        "    if 'session_service_stateful' in globals():\n",
        "        runner_root_tool_guardrail = Runner(\n",
        "            agent=root_agent_tool_guardrail,\n",
        "            app_name=APP_NAME,\n",
        "            session_service=session_service_stateful # <<< Use the service from Step 4/5\n",
        "        )\n",
        "        print(f\"✅ Runner created for tool guardrail agent '{runner_root_tool_guardrail.agent.name}', using stateful session service.\")\n",
        "    else:\n",
        "        print(\"❌ Cannot create runner. 'session_service_stateful' from Step 4/5 is missing.\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ Cannot create root agent with tool guardrail. Prerequisites missing.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8BVIl_3uLTZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7df8f3-1afe-4136-bcae-2ca981b058c9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sub-Agent 'greeting_agent' redefined.\n",
            "✅ Sub-Agent 'farewell_agent' redefined.\n",
            "✅ Root Agent 'weather_agent_v6_tool_guardrail' created with BOTH callbacks.\n",
            "✅ Runner created for tool guardrail agent 'weather_agent_v6_tool_guardrail', using stateful session service.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "** 3 \\.Interactuar para probar la barandilla de la herramienta **\n",
        "\n",
        "Probemos el flujo de interacción, nuevamente utilizando la misma sesión de estado (`session_id_stateful`) desde los pasos anteriores.\n",
        "\n",
        "1. Solicite el clima de \"Nueva York\": pasa ambas devoluciones de llamada, se ejecuta la herramienta (usando la preferencia de Fahrenheit del estado).\n",
        "2. Solicite el clima de \"París\": pasa `antes_model_callback`.LLM decide llamar a `get_weather_stateful (ciudad = 'paris')`.`antes_tool_callback` intercepta, bloquea la herramienta y devuelve el diccionario de error.Agente transmite este error.\n",
        "3. Solicite clima para \"Londres\": pasa ambas devoluciones de llamada, la herramienta se ejecuta normalmente."
      ],
      "metadata": {
        "id": "aUo-nu657kc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Title 3. Interactuar para probar la barandilla del argumento de la herramienta\n",
        "\n",
        "# Asegúrese de que el corredor para el agente de la barandilla de la herramienta esté disponible\n",
        "if runner_root_tool_guardrail:\n",
        "  async def run_tool_guardrail_test():\n",
        "      print(\"\\n--- Testing Tool Argument Guardrail ('Paris' blocked) ---\")\n",
        "\n",
        "# # Use el corredor para el agente con las devoluciones de llamada y la sesión de estado existente\n",
        "      interaction_func = lambda query: call_agent_async(query,\n",
        "      runner_root_tool_guardrail, USER_ID_STATEFUL, SESSION_ID_STATEFUL\n",
        "  )\n",
        "# # 1. Ciudad permitida (debería pasar ambas devoluciones de llamada, usar el estado de Fahrenheit)\n",
        "      await interaction_func(\"What's the weather in New York?\")\n",
        "\n",
        "# # 2. Ciudad bloqueada (debe pasar la devolución de llamada del modelo, pero estar bloqueado por la devolución de llamada de la herramienta)\n",
        "      await interaction_func(\"How about Paris?\")\n",
        "\n",
        "# # 3. Otra ciudad permitida (debería volver a funcionar normalmente)\n",
        "      await interaction_func(\"Tell me the weather in London.\")\n",
        "\n",
        "# # Ejecutar la conversación\n",
        "  await run_tool_guardrail_test()\n",
        "\n",
        "# # Opcional: Verifique el estado de la bandera de activación del bloque de herramientas\n",
        "  final_session = session_service_stateful.get_session(app_name=APP_NAME,\n",
        "                                                       user_id=USER_ID_STATEFUL,\n",
        "                                                       session_id= SESSION_ID_STATEFUL)\n",
        "  if final_session:\n",
        "      print(\"\\n--- Final Session State (After Tool Guardrail Test) ---\")\n",
        "      print(f\"Tool Guardrail Triggered Flag: {final_session.state.get('guardrail_tool_block_triggered')}\")\n",
        "      print(f\"Last Weather Report: {final_session.state.get('last_weather_report')}\") # Should be London weather\n",
        "      print(f\"Temperature Unit: {final_session.state.get('user_preference_temperature_unit')}\") # Should be Fahrenheit\n",
        "  else:\n",
        "      print(\"\\n❌ Error: Could not retrieve final session state.\")\n",
        "\n",
        "else:\n",
        "  print(\"\\n⚠️ Skipping tool guardrail test. Runner ('runner_root_tool_guardrail') is not available.\")"
      ],
      "metadata": {
        "id": "wpg4fzkLav1-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b707589a-b6f7-48b1-e57a-960d9ffb8121"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google.adk.tools.function_parameter_parse_util:Default value is not supported in function declaration schema for Google AI.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Testing Tool Argument Guardrail ('Paris' blocked) ---\n",
            "\n",
            ">>> User Query: What's the weather in New York?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'For context:...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Callback: block_paris_tool_guardrail running for tool 'get_weather_stateful' in agent 'weather_agent_v6_tool_guardrail' ---\n",
            "--- Callback: Inspecting args: {'city': 'New York'} ---\n",
            "--- Callback: City 'New York' is allowed for tool 'get_weather_stateful'. ---\n",
            "--- Callback: Allowing tool 'get_weather_stateful' to proceed. ---\n",
            "--- Tool: get_weather_stateful called for New York ---\n",
            "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
            "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in New york is sunny with a temperature of 77°F.'} ---\n",
            "--- Tool: Updated state 'last_city_checked_stateful': New York ---\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'For context:...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n",
            "<<< Agent Response: The weather in New york is sunny with a temperature of 77°F.\n",
            "\n",
            "\n",
            ">>> User Query: How about Paris?\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'How about Paris?...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Callback: block_paris_tool_guardrail running for tool 'get_weather_stateful' in agent 'weather_agent_v6_tool_guardrail' ---\n",
            "--- Callback: Inspecting args: {'city': 'Paris'} ---\n",
            "--- Callback: Detected blocked city 'Paris'. Blocking tool execution! ---\n",
            "--- Callback: Set state 'guardrail_tool_block_triggered': True ---\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'How about Paris?...' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n",
            "<<< Agent Response: I am sorry, I cannot process the request for Paris due to a policy restriction.\n",
            "\n",
            "\n",
            ">>> User Query: Tell me the weather in London.\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'Tell me the weather in London....' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Callback: block_paris_tool_guardrail running for tool 'get_weather_stateful' in agent 'weather_agent_v6_tool_guardrail' ---\n",
            "--- Callback: Inspecting args: {'city': 'London'} ---\n",
            "--- Callback: City 'London' is allowed for tool 'get_weather_stateful'. ---\n",
            "--- Callback: Allowing tool 'get_weather_stateful' to proceed. ---\n",
            "--- Tool: get_weather_stateful called for London ---\n",
            "--- Tool: Reading state 'user_preference_temperature_unit': Fahrenheit ---\n",
            "--- Tool: Generated report in Fahrenheit. Result: {'status': 'success', 'report': 'The weather in London is cloudy with a temperature of 59°F.'} ---\n",
            "--- Tool: Updated state 'last_city_checked_stateful': London ---\n",
            "--- Callback: block_keyword_guardrail running for agent: weather_agent_v6_tool_guardrail ---\n",
            "--- Callback: Inspecting last user message: 'Tell me the weather in London....' ---\n",
            "--- Callback: Keyword not found. Allowing LLM call for weather_agent_v6_tool_guardrail. ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ClientError",
          "evalue": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-6a3f9c127e9f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# # Ejecutar la conversación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0;32mawait\u001b[0m \u001b[0mrun_tool_guardrail_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# # Opcional: Verifique el estado de la bandera de activación del bloque de herramientas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-6a3f9c127e9f>\u001b[0m in \u001b[0;36mrun_tool_guardrail_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# # 3. Otra ciudad permitida (debería volver a funcionar normalmente)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0;32mawait\u001b[0m \u001b[0minteraction_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tell me the weather in London.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# # Ejecutar la conversación\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-9ba36bdb48dd>\u001b[0m in \u001b[0;36mcall_agent_async\u001b[0;34m(query, runner, user_id, session_id)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# # Concepto de clave: Run_async ejecuta la lógica del agente y produce eventos.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# # Nos iteramos a través de eventos para encontrar la respuesta final.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# # Puede desenchufar la línea a continuación para ver * todos * eventos durante la ejecución\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# # print (f \"[evento] autor: {event.author}, type: {type (evento) .__ name__}, final: {event.is_final_esponse ()}, content: {event.content}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, user_id, session_id, new_message, run_config)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m       \u001b[0minvocation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_agent_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minvocation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_service\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, parent_context)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_async_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\u001b[0m in \u001b[0;36m_run_async_impl\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInvocationContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m   ) -> AsyncGenerator[Event, None]:\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_llm_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__maybe_save_output_to_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36mrun_async\u001b[0;34m(self, invocation_context)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0mlast_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m       \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_step_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvocation_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mlast_event\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_run_one_step_async\u001b[0;34m(self, invocation_context)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mbranch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minvocation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     )\n\u001b[0;32m--> 257\u001b[0;31m     async for llm_response in self._call_llm_async(\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0minvocation_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_response_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     ):\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\u001b[0m in \u001b[0;36m_call_llm_async\u001b[0;34m(self, invocation_context, llm_request, model_response_event)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# right here, and exception is thrown.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0minvocation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_llm_call_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         async for llm_response in llm.generate_content_async(\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mllm_request\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minvocation_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreaming_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\u001b[0m in \u001b[0;36mgenerate_content_async\u001b[0;34m(self, llm_request, stream)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       response = await self.api_client.aio.models.generate_content(\n\u001b[0m\u001b[1;32m    141\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m           \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   6413\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6414\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mremaining_remote_calls_afc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6415\u001b[0;31m       response = await self._generate_content(\n\u001b[0m\u001b[1;32m   6416\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6417\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/models.py\u001b[0m in \u001b[0;36m_generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5412\u001b[0m     \u001b[0mrequest_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_unserializable_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5414\u001b[0;31m     response_dict = await self._api_client.async_request(\n\u001b[0m\u001b[1;32m   5415\u001b[0m         \u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5416\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36masync_request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m    687\u001b[0m     )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\u001b[0m in \u001b[0;36m_async_request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    631\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhttp_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m       )\n\u001b[0;32m--> 633\u001b[0;31m       \u001b[0;32mawait\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_async_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m       return HttpResponse(\n\u001b[1;32m    635\u001b[0m           \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\u001b[0m in \u001b[0;36mraise_for_async_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mstatus_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mClientError\u001b[0m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash-exp'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Analizar la salida:\n",
        "\n",
        "1. ** Nueva York: ** El `antes_model_callback` permite la solicitud.El LLM solicita `get_weather_stateful`.El `antes_tool_callback` se ejecuta, inspecciona los args (` {'City': 'Nueva York'} `), ve que no es\" París \", imprime\" Permitir la herramienta ... \"y devuelve` Ninguno`.La función real `get_weather_stateful` se ejecuta, lee\" fahrenheit \"del estado y devuelve el informe meteorológico.El agente transmite esto, y se guarda a través de `output_key`.\n",
        "2. ** París: ** El `antes_model_callback` permite la solicitud.El LLM solicita `get_weather_stateful (ciudad = 'paris')`.El `antes_tool_callback` se ejecuta, inspecciona los args, detecta\" París \", imprime\" Ejecución de la herramienta de bloqueo \\! \", Establece el indicador de estado y devuelve el Diccionario de error` {'status': 'Error', 'Error_message': 'Reducción de la política ...'} `.La función real `get_weather_stateful` es ** nunca ejecutada **.El agente recibe el diccionario de error * como si fuera la salida de la herramienta * y formula una respuesta basada en ese mensaje de error.\n",
        "3. ** Londres: ** se comporta como Nueva York, pasando las devoluciones de llamada y ejecutando la herramienta con éxito.El New London Weather Report sobrescribe el 'Last_Weather_report` en el estado.\n",
        "\n",
        "Ahora ha agregado una capa de seguridad crucial que controla no solo * lo que * alcanza el LLM, sino también * cómo * las herramientas del agente pueden usarse en función de los argumentos específicos generados por el LLM.Las devoluciones de llamada como `antes_model_callback` y` antes_tool_callback` son esenciales para construir aplicaciones de agente robustas, seguras y compatibles con políticas."
      ],
      "metadata": {
        "id": "6gCcBgMfa1VS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "## Conclusión: ¡Su equipo de agente está listo!\n",
        "\n",
        "¡Felicidades!Ha viajado con éxito desde la construcción de un agente meteorológico único y básico hasta la construcción de un equipo sofisticado de múltiples agentes utilizando el Kit de desarrollo de agentes (ADK).\n",
        "\n",
        "** Recapitulemos lo que has logrado: **\n",
        "\n",
        "*Comenzó con un agente fundamental ** ** equipado con una sola herramienta (`get_weather`).\n",
        "*Exploró la flexibilidad multimodelo ** de ADK ** usando litellm, ejecutando la misma lógica central con diferentes LLM como Gemini, GPT-4O y Claude.\n",
        "*Usted abrazó ** modularidad ** creando subcrescantes especializados (`saludo_agent`,` Farewell_agent`) y habilitando ** la delegación automática ** de un agente raíz.\n",
        "*Le dio a sus agentes ** Memoria ** usando el estado de la sesión ** **, lo que les permite recordar las preferencias del usuario (`temperatura_unit`) y las interacciones pasadas (` `°_key`).\n",
        "*Implementó Cross ** Safety BuardRails ** usando tanto `antes_model_callback (bloqueando palabras clave de entrada específicas) como` antes_tool_callback` (ejecución de la herramienta de bloqueo basada en argumentos como la ciudad \"París\").\n",
        "\n",
        "A través de la construcción de este equipo progresivo de botes meteorológicos, ha adquirido experiencia práctica con conceptos de ADK centrales esenciales para desarrollar aplicaciones complejas e inteligentes.\n",
        "\n",
        "** Control de llave: **\n",
        "\n",
        "*** Agentes y herramientas: ** Los bloques de construcción fundamentales para definir capacidades y razonamiento.Las instrucciones y las documentos claras son primordiales.\n",
        "*** Corredores y servicios de sesión: ** El sistema de gestión del motor y la memoria que orquesta la ejecución del agente y mantiene el contexto de conversación.\n",
        "*** Delegación: ** El diseño de equipos de múltiples agentes permite especialización, modularidad y una mejor gestión de tareas complejas.El agente `Descripción` es clave para el flujo automático.\n",
        "*** Estado de sesión (`ToolContext`,` Output_Key`): ** Esencial para crear agentes conversacionales con el contexto, personalizados y de múltiples vueltas.\n",
        "*** Callbacks (`antes_model`,` antes_tool`): ** ganchos potentes para implementar seguridad, validación, aplicación de políticas y modificaciones dinámicas*antes de*operaciones críticas (llamadas LLM o ejecución de herramientas).\n",
        "*** Flexibilidad (`litellm`): ** ADK le permite elegir el mejor LLM para el trabajo, el rendimiento de equilibrio, el costo y las funciones.\n",
        "\n",
        "** ¿A dónde ir después? **\n",
        "\n",
        "Su equipo de botes meteorológicos es un gran punto de partida.Aquí hay algunas ideas para explorar más a fondo y mejorar su aplicación:\n",
        "\n",
        "1. ** API del clima real: ** Reemplace la herramienta `Mock_weather_DB` en su herramienta 'Get_Weather` con una llamada a una API del clima real (como OpenWeathermap, Weatherapi).\n",
        "2. ** Estado más complejo: ** Almacene más preferencias del usuario (por ejemplo, ubicación preferida, configuración de notificación) o resúmenes de conversación en el estado de la sesión.\n",
        "3. ** Refina Delegación: ** Experimentar con diferentes instrucciones de agente raíz o descripciones de subagentes para ajustar la lógica de la delegación.¿Podría agregar un agente de \"pronóstico\"?\n",
        "4. ** Backbacks avanzadas: **\n",
        "* Use `After_model_callback` para reformatear o desinfectar la respuesta de la LLM * después de * se genera.\n",
        "* Use `After_Tool_Callback` para procesar o registrar los resultados devueltos por una herramienta.\n",
        "* Implementar `antes_agent_callback` o` después_agent_callback` para la lógica de entrada/salida de nivel de agente.\n",
        "5. ** Manejo de errores: ** Mejore cómo el agente maneja errores de herramienta o respuestas de API inesperadas.Tal vez agregue la lógica de reintento dentro de una herramienta.\n",
        "6. ** Almacenamiento de sesión persistente: ** Explore alternativas a `InMemorySessionService` para almacenar el estado de la sesión de manera persistente (por ejemplo, el uso de bases de datos como Firestore o Cloud SQL, requiere implementación personalizada o integraciones de ADK futuras).\n",
        "7. ** CLUYING US: ** Integre su equipo de agentes con un marco web (como Fastapi, como se muestra en la transmisión de ADK, CapidStart) para crear una interfaz de chat en tiempo real.\n",
        "\n",
        "El kit de desarrollo de agentes proporciona una base robusta para construir aplicaciones sofisticadas con alimentación LLM.Al dominar los conceptos cubiertos en este tutorial (herramientas, estado, delegación y devoluciones de llamada, está bien equipado para abordar sistemas de agente cada vez más complejos.\n",
        "\n",
        "¡Feliz edificio!"
      ],
      "metadata": {
        "id": "xYWtGbdI8DZw"
      }
    }
  ]
}